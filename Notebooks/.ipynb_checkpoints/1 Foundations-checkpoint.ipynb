{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference Examples\n",
    "# 1 Foundations\n",
    "Julian Hsu\n",
    "Date Made: 5 Aug 2021 \n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write Causal Models](#Section1)\n",
    "* [Simulate Data](#Section2)\n",
    "* [Bootstrapping Examples](#Section3)\n",
    "* [Bootstrapping Examples - unconfoundedness violation](#Section4)\n",
    "* [Bootstrapping Examples - overlap violation](#Section5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "\n",
    "## Write Causal Models\n",
    "Write several functions here for estimate HTE. Each model _must_ do datasplitting.\n",
    "These functions will do a lot of predictions, so try to standardize the prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stnomics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "## Bring in Simulated Data\n",
    "Pretend we've never seen this data before, and do balance checks between treatment and control \n",
    "\n",
    "For fun, use the Friedman function: https://www.sfu.ca/~ssurjano/fried.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    N = 2000\n",
    "    \n",
    "    cov = [[1.00, 0.08, 0.05, 0.05],\n",
    "           [0.08, 1.00,-0.08,-0.02],\n",
    "           [0.05,-0.08, 1.00,-0.10],\n",
    "           [0.05,-0.02,-0.10, 1.00]]\n",
    "    cov = np.eye(4)\n",
    "    X = np.random.multivariate_normal(np.zeros(4), cov,N)\n",
    "    x1,x2,x3,x4= X[:,0],X[:,1],X[:,2],X[:,3]\n",
    "\n",
    "    treatment_latent = 2*np.sin( np.pi * x4 * x3) + 10*(x2-0.5)**2 - 10*x1\n",
    "    m,s = np.average(treatment_latent), np.std(treatment_latent)\n",
    "\n",
    "    treatment_latent = (treatment_latent - m) / s\n",
    "    \n",
    "    random_t = np.random.normal(0,1,N)\n",
    "    \n",
    "    treatment_latent += random_t\n",
    "    \n",
    "    treatment = np.array( np.exp(treatment_latent) / (1+ np.exp(treatment_latent)) > np.random.uniform(0,1,N) ).astype(np.int32)\n",
    "\n",
    "#     Y = 100 +0.5*x1 - 6*x2 + -2*x4*x1 + 0.5*x1*x2 - 7*(x3+1)**(0.5) + 8/(0.5+x3+x4)\n",
    "    Y = 100 + 10*np.sin( np.pi * x1 * x2) + 20*(x3-0.5)**2 - 10*x4\n",
    "#     GT = np.std(Y)\n",
    "    random_y = np.random.normal(0,1,N)\n",
    "\n",
    "    GT = 5\n",
    "    Y += np.random.normal(1,2,N)\n",
    "    Y += GT*(treatment==1) \n",
    "    \n",
    "    df_est = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'treatment':treatment, 'Y':Y, 'GT':GT} )\n",
    "    df_est['x1_2'] = df_est['x1'].pow(2)\n",
    "    df_est['x2_2'] = df_est['x2'].pow(2)\n",
    "    df_est['x3_2'] = df_est['x3'].pow(2)\n",
    "    df_est['x4_2'] = df_est['x4'].pow(2)    \n",
    "    return df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Y</th>\n",
       "      <th>GT</th>\n",
       "      <th>x1_2</th>\n",
       "      <th>x2_2</th>\n",
       "      <th>x3_2</th>\n",
       "      <th>x4_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.313283</td>\n",
       "      <td>-0.489695</td>\n",
       "      <td>0.563628</td>\n",
       "      <td>-0.324982</td>\n",
       "      <td>1</td>\n",
       "      <td>105.700209</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098146</td>\n",
       "      <td>0.239801</td>\n",
       "      <td>0.317676</td>\n",
       "      <td>0.105613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347911</td>\n",
       "      <td>0.829529</td>\n",
       "      <td>0.863875</td>\n",
       "      <td>-0.082179</td>\n",
       "      <td>1</td>\n",
       "      <td>102.593495</td>\n",
       "      <td>5</td>\n",
       "      <td>0.121042</td>\n",
       "      <td>0.688119</td>\n",
       "      <td>0.746279</td>\n",
       "      <td>0.006753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.674069</td>\n",
       "      <td>1.074357</td>\n",
       "      <td>0.852527</td>\n",
       "      <td>0.582977</td>\n",
       "      <td>0</td>\n",
       "      <td>105.036677</td>\n",
       "      <td>5</td>\n",
       "      <td>2.802507</td>\n",
       "      <td>1.154242</td>\n",
       "      <td>0.726802</td>\n",
       "      <td>0.339862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288611</td>\n",
       "      <td>-0.335995</td>\n",
       "      <td>-1.054658</td>\n",
       "      <td>-0.091539</td>\n",
       "      <td>0</td>\n",
       "      <td>144.336512</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083296</td>\n",
       "      <td>0.112893</td>\n",
       "      <td>1.112303</td>\n",
       "      <td>0.008379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.972706</td>\n",
       "      <td>0.119425</td>\n",
       "      <td>-1.156609</td>\n",
       "      <td>-0.030407</td>\n",
       "      <td>0</td>\n",
       "      <td>152.401670</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>1.337744</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.644172</td>\n",
       "      <td>-0.381519</td>\n",
       "      <td>2.104919</td>\n",
       "      <td>-0.124986</td>\n",
       "      <td>0</td>\n",
       "      <td>158.054612</td>\n",
       "      <td>5</td>\n",
       "      <td>0.414957</td>\n",
       "      <td>0.145557</td>\n",
       "      <td>4.430683</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.018871</td>\n",
       "      <td>-1.890406</td>\n",
       "      <td>0.717081</td>\n",
       "      <td>1.377236</td>\n",
       "      <td>1</td>\n",
       "      <td>96.820982</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>3.573634</td>\n",
       "      <td>0.514205</td>\n",
       "      <td>1.896778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.782518</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.079507</td>\n",
       "      <td>0.643935</td>\n",
       "      <td>1</td>\n",
       "      <td>97.958290</td>\n",
       "      <td>5</td>\n",
       "      <td>0.612335</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.414652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-1.698061</td>\n",
       "      <td>-0.853848</td>\n",
       "      <td>0.383134</td>\n",
       "      <td>1.211971</td>\n",
       "      <td>1</td>\n",
       "      <td>81.896919</td>\n",
       "      <td>5</td>\n",
       "      <td>2.883411</td>\n",
       "      <td>0.729056</td>\n",
       "      <td>0.146792</td>\n",
       "      <td>1.468875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.783112</td>\n",
       "      <td>0.654464</td>\n",
       "      <td>0.445458</td>\n",
       "      <td>-0.876325</td>\n",
       "      <td>1</td>\n",
       "      <td>119.786695</td>\n",
       "      <td>5</td>\n",
       "      <td>3.179490</td>\n",
       "      <td>0.428324</td>\n",
       "      <td>0.198432</td>\n",
       "      <td>0.767946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4  treatment           Y  GT  \\\n",
       "0     0.313283 -0.489695  0.563628 -0.324982          1  105.700209   5   \n",
       "1    -0.347911  0.829529  0.863875 -0.082179          1  102.593495   5   \n",
       "2    -1.674069  1.074357  0.852527  0.582977          0  105.036677   5   \n",
       "3     0.288611 -0.335995 -1.054658 -0.091539          0  144.336512   5   \n",
       "4    -0.972706  0.119425 -1.156609 -0.030407          0  152.401670   5   \n",
       "...        ...       ...       ...       ...        ...         ...  ..   \n",
       "1995 -0.644172 -0.381519  2.104919 -0.124986          0  158.054612   5   \n",
       "1996 -0.018871 -1.890406  0.717081  1.377236          1   96.820982   5   \n",
       "1997  0.782518 -0.175322 -0.079507  0.643935          1   97.958290   5   \n",
       "1998 -1.698061 -0.853848  0.383134  1.211971          1   81.896919   5   \n",
       "1999 -1.783112  0.654464  0.445458 -0.876325          1  119.786695   5   \n",
       "\n",
       "          x1_2      x2_2      x3_2      x4_2  \n",
       "0     0.098146  0.239801  0.317676  0.105613  \n",
       "1     0.121042  0.688119  0.746279  0.006753  \n",
       "2     2.802507  1.154242  0.726802  0.339862  \n",
       "3     0.083296  0.112893  1.112303  0.008379  \n",
       "4     0.946158  0.014262  1.337744  0.000925  \n",
       "...        ...       ...       ...       ...  \n",
       "1995  0.414957  0.145557  4.430683  0.015621  \n",
       "1996  0.000356  3.573634  0.514205  1.896778  \n",
       "1997  0.612335  0.030738  0.006321  0.414652  \n",
       "1998  2.883411  0.729056  0.146792  1.468875  \n",
       "1999  3.179490  0.428324  0.198432  0.767946  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 500\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1,  random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_splits = 4\n",
    "aux_dictionary = {'n_bins': 2, 'n_trees':2, 'max_depth':2, \n",
    "                  'upper':0.999, 'lower':0.001,\n",
    "                  'bootstrapreps':100,\n",
    "                  'subsample_ratio':0.5}\n",
    "bootstrap_number = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "\n",
    "feature_list = [x for x in df.columns if 'x' in x]\n",
    "\n",
    "ols = st.ate.ols_vanilla(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "pbin = st.ate.propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "plm = st.ate.dml.dml_plm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "irm = st.ate.dml.dml_irm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "df = df.sort_values(by='splits')    \n",
    "\n",
    "## Predict Treatment\n",
    "that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "df['that'] = that\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n",
    "control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "print(control_range_to_remove)\n",
    "\n",
    "df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "\n",
    "## Bootstrapping\n",
    "* Bootstrap results using random datasets when all three assumptions are satisfied.\n",
    "* Bootstrap results when the unconfoundedness assumption is violated. Do this by removing one fot the features from training.\n",
    "* Bootstrap results when the overlap assumption is violated. Do this by removing control observations with propensities near the median treatment obervation propensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x = []\n",
    "pbin_x= []\n",
    "plm_x = []\n",
    "irm_x = []\n",
    "ipw_x = []\n",
    "\n",
    "ols_x_unconf = []\n",
    "pbin_x_unconf= []\n",
    "plm_x_unconf = []\n",
    "irm_x_unconf = []\n",
    "ipw_x_unconf = []\n",
    "\n",
    "ols_x_overlap = []\n",
    "pbin_x_overlap= []\n",
    "plm_x_overlap = []\n",
    "irm_x_overlap = []\n",
    "ipw_x_overlap = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(bootstrap_number):\n",
    "    df = generate_data()\n",
    "    \n",
    "    feature_list = [x for x in df.columns if 'x' in x]\n",
    "    \n",
    "    feature_list_ab = [x for x in feature_list if '3' not in x and '4' not in x]\n",
    "    \n",
    "    ## Regular \n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x.append(ols['ATE TE'])\n",
    "    pbin_x.append(pbin['ATE TE'])\n",
    "    plm_x.append(plm['ATE TE'])\n",
    "    irm_x.append(irm['ATE TE'])    \n",
    "    ipw_x.append(ip['ATE TE'])   \n",
    "    \n",
    "    ## When unconfoundedness assumption is not true\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x_unconf.append(ols['ATE TE'])\n",
    "    pbin_x_unconf.append(pbin['ATE TE'])\n",
    "    plm_x_unconf.append(plm['ATE TE'])\n",
    "    irm_x_unconf.append(irm['ATE TE'])    \n",
    "    ipw_x_unconf.append(ip['ATE TE'])        \n",
    "\n",
    "\n",
    "    ## When overlap condition is not true\n",
    "    df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "    df = df.sort_values(by='splits')    \n",
    "    ## Predict Treatment\n",
    "    that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "    df['that'] = that    \n",
    "    control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "    df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "\n",
    "\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "\n",
    "    ols_x_overlap.append(ols['ATE TE'])\n",
    "    pbin_x_overlap.append(pbin['ATE TE'])\n",
    "    plm_x_overlap.append(plm['ATE TE'])\n",
    "    irm_x_overlap.append(irm['ATE TE'])    \n",
    "    ipw_x_overlap.append(ip['ATE TE'])        \n",
    "\n",
    "ols_x = np.array(ols_x) - 5\n",
    "pbin_x = np.array(pbin_x) - 5\n",
    "plm_x = np.array(plm_x) - 5\n",
    "irm_x = np.array(irm_x) - 5\n",
    "ipw_x = np.array(ipw_x) - 5\n",
    "\n",
    "ols_x_unconf = np.array(ols_x_unconf) - 5\n",
    "pbin_x_unconf = np.array(pbin_x_unconf) - 5\n",
    "plm_x_unconf = np.array(plm_x_unconf) - 5\n",
    "irm_x_unconf = np.array(irm_x_unconf) - 5\n",
    "ipw_x_unconf = np.array(ipw_x_unconf) - 5    \n",
    "\n",
    "ols_x_overlap = np.array(ols_x_overlap) - 5\n",
    "pbin_x_overlap = np.array(pbin_x_overlap) - 5\n",
    "plm_x_overlap = np.array(plm_x_overlap) - 5\n",
    "irm_x_overlap = np.array(irm_x_overlap) - 5\n",
    "ipw_x_overlap = np.array(ipw_x_overlap) - 5    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_med_iqr(x):\n",
    "    avg = np.average(x)\n",
    "    p50 = np.percentile(x, 50)\n",
    "    p25 = np.percentile(x, 25)\n",
    "    p75 = np.percentile(x, 75)    \n",
    "    print('AVG: {0:5.2f}   MED: {1:5.2f}   IQR: [{2:5.3f}, {3:5.2f}]'.format(avg, p50, p25, p75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bias when all assumptions are met')\n",
    "print_avg_med_iqr(ols_x)    \n",
    "print_avg_med_iqr(pbin_x)    \n",
    "print_avg_med_iqr(plm_x)    \n",
    "print_avg_med_iqr(irm_x)    \n",
    "print_avg_med_iqr(ipw_x)    \n",
    "\n",
    "print('')\n",
    "print('Bias when unconfoundedness is not met')\n",
    "print_avg_med_iqr(ols_x_unconf) \n",
    "print_avg_med_iqr(pbin_x_unconf)    \n",
    "print_avg_med_iqr(plm_x_unconf)    \n",
    "print_avg_med_iqr(irm_x_unconf)    \n",
    "print_avg_med_iqr(ipw_x_unconf)    \n",
    "\n",
    "print('')\n",
    "print('Bias when overlap is not met')\n",
    "print_avg_med_iqr(ols_x_overlap)    \n",
    "print_avg_med_iqr(pbin_x_overlap)    \n",
    "print_avg_med_iqr(plm_x_overlap)    \n",
    "print_avg_med_iqr(irm_x_overlap)    \n",
    "print_avg_med_iqr(ipw_x_overlap[~np.isnan(ipw_x_overlap)])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "\n",
    "## Prediction vs Causal\n",
    "Let's compare the estimated treatment effects $\\hat{Y}(W=1) - \\hat{Y}(W=0) $ among ML models. Let's use the treatment effect of multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(WDim=2,\n",
    "             TE = [1,1],\n",
    "             N = 50):\n",
    "    corr = False\n",
    "    \n",
    "    if corr==False:\n",
    "        W1 = np.random.randint(0,2, N) \n",
    "        W2 = np.random.randint(0,2, N)     \n",
    "    else:\n",
    "        x = np.random.uniform(0,1,N)\n",
    "        x1 = np.random.uniform(-1,1,N)\n",
    "        x2 = np.random.uniform(-1,1,N)        \n",
    "        W1 = ( ( np.exp(x + x1) / (1+ np.exp(x+x1)) ) > np.random.uniform(0.45,0.55) ).astype(float)\n",
    "        W2 = ( ( np.exp(x + x2) / (1+ np.exp(x+x2)) ) > np.random.uniform(0.45,0.55) ).astype(float)        \n",
    "        \n",
    "\n",
    "    Y = TE[0]*W1 + TE[1]*W2 + np.random.normal(0,1, N)\n",
    "    return pd.DataFrame(data={'Y':Y, 'W1':W1, 'W2': W2}, index=np.arange(N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_te(X, func):\n",
    "    trained = func.fit(X[['W1','W2']], X['Y'])\n",
    "    te1 = trained.predict([[1,0]]) - trained.predict([[0,0]])\n",
    "    te2 = trained.predict([[0,1]]) - trained.predict([[0,0]])    \n",
    "    return te1[0], te2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = MLPRegressor(hidden_layer_sizes=(2,), max_iter = 2000, random_state=4227)\n",
    "nn10 = MLPRegressor(hidden_layer_sizes=(10,), max_iter = 2000, random_state=4227)\n",
    "ols = LinearRegression()\n",
    "rf1000 = RandomForestRegressor(n_estimators=1000)\n",
    "rf100 = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Data and simulate many OLS and other estimates\n",
    "TE_use = [0.05,0.05] \n",
    "dict_est1 = {'OLS':[], 'NN2':[], 'NN10':[], 'RF1000':[], 'RF100':[]  }\n",
    "dict_est2 = {'OLS':[], 'NN2':[], 'NN10':[], 'RF1000':[], 'RF100':[]  }\n",
    "\n",
    "for r in range(1000):\n",
    "    df = sim_data(WDim=2, TE = TE_use, N = 100)\n",
    "    # display(df.describe())\n",
    "    ols1, ols2 = ml_te(df, ols)\n",
    "    nn2_1,  nn2_2 = ml_te(df, nn2)\n",
    "    nn10_1,  nn10_2 = ml_te(df, nn10)\n",
    "    rf1000_1,  rf1000_2 = ml_te(df, rf1000)\n",
    "    rf100_1,  rf100_2 = ml_te(df, rf100)\n",
    "\n",
    "    dict_est1['OLS'].append(ols1)\n",
    "    dict_est2['OLS'].append(ols2)\n",
    "\n",
    "    dict_est1['NN2'].append(nn2_1)\n",
    "    dict_est2['NN2'].append(nn2_2)\n",
    "\n",
    "    dict_est1['NN10'].append(nn10_1)\n",
    "    dict_est2['NN10'].append(nn10_2)\n",
    "\n",
    "    dict_est1['RF1000'].append(rf1000_1)\n",
    "    dict_est2['RF1000'].append(rf1000_2)\n",
    "\n",
    "    dict_est1['RF100'].append(rf100_1)\n",
    "    dict_est2['RF100'].append(rf100_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.23607439211512976]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_est1['OLS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estimate 2')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(8,8), sharex=True, sharey=True)\n",
    "ax[0].hist(dict_est1['OLS'],   density=False,  label='ols',           alpha=0.25, color='coral')\n",
    "ax[0].hist(dict_est1['NN2'],   density=False,  label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "ax[0].hist(dict_est1['NN10'],  density=False,  label='neural net 10', alpha=0.25, color='lime')\n",
    "ax[0].hist(dict_est1['RF1000'],density=False,  label='RF 1000',       alpha=0.25,  color='navy')\n",
    "ax[0].hist(dict_est1['RF100'], density=False,  label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "ax[0].vlines(TE_use[0], 0, 500, colors='black', label='Truth')\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Estimate 1')\n",
    "\n",
    "ax[1].hist(dict_est2['OLS'],   density=False, label='ols',           alpha=0.25, color='coral')\n",
    "ax[1].hist(dict_est2['NN2'],   density=False, label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "ax[1].hist(dict_est2['NN10'],  density=False, label='neural net 10', alpha=0.25, color='lime')\n",
    "ax[1].hist(dict_est2['RF1000'],density=False, label='RF 1000',       alpha=0.25,  color='navy')\n",
    "ax[1].hist(dict_est2['RF100'], density=False, label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "ax[1].vlines(TE_use[1], 0, 500, colors='black', label='Truth')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Estimate 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
