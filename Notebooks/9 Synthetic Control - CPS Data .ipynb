{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfa87ee",
   "metadata": {},
   "source": [
    "# 9 Synthetic Control - CPS Data\n",
    "Julian Hsu\n",
    "4apr2022\n",
    "\n",
    "Create state-month level CPS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0e8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82597c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hsujulia/Downloads/CPSData'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4c06c",
   "metadata": {},
   "source": [
    "CPS data are downloaded on local drive. You can find the CPS files from here: https://data.nber.org/cps-basic2/docs/\n",
    "\n",
    "Data codebook is here: https://data.nber.org/cps-basic2/docs/cpsb202001.ddf\n",
    "\n",
    "Need to know:\n",
    "\n",
    "| variable name | description |\n",
    "| :--- | :--- |\n",
    "| GESTFIPS | state |\n",
    "| PWSSWGT  | final weight |\n",
    "| HRMONTH  | Month of data|\n",
    "| HRYEAR4  | Year of data |\n",
    "| HEFAMINC | Family Income bracket |\n",
    "| PRERNWA  | Weekly earnings| \n",
    "| PRTAGE   | Age| \n",
    "| PEMLR    | MONTHLY LABOR FORCE | \n",
    "| PEERNHRY | Whether earnings are hourly | \n",
    "| PUERNH1C | hourly wage |\n",
    "| PRWKSTAT | Part-time full time status| \n",
    "| PERET1   | Eligibiligy (whether want a part-time job)| \n",
    "| HRHTYPE  | Married| \n",
    "| HETENURE | Living quarters are rent| \n",
    "| PEEDUCA  | Highest level of school completed| \n",
    "| PTDTRACE | Race| \n",
    "| PENATVTY | Country of birth| \n",
    "| PRAGNA   | Worked in agriculture| \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27940b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a233dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/hsujulia/Downloads/CPSData')\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "cps_files = [f for f in listdir(os.getcwd()) if isfile(join(os.getcwd(), f)) and 'cps' in f]\n",
    "\n",
    "column_list = [\n",
    "'GESTFIPS',\n",
    "'PWSSWGT',\n",
    "'HRMONTH',\n",
    "'HRYEAR4',\n",
    "'HEFAMINC',\n",
    "'PRERNWA',\n",
    "'PRTAGE',\n",
    "'PEMLR',\n",
    "'PEERNHRY',\n",
    "'PUERNH1C', \n",
    "'PRWKSTAT',\n",
    "'PERET1',\n",
    "'HRHTYPE',\n",
    "'HETENURE',\n",
    "'PEEDUCA',\n",
    "'PTDTRACE',\n",
    "'PENATVTY',\n",
    "'PRAGNA']\n",
    "column_list = [x.lower() for x in column_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f15df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_output = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c743106",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cps_files:\n",
    "    df = pd.read_csv(c)[column_list]\n",
    "    ## Replace negative numbers with missing\n",
    "    df.replace(to_replace=[-2,-1], value=np.NaN, inplace=True)\n",
    "\n",
    "    ## State    \n",
    "    df['state'] = df['gestfips'].replace( {1:'AL', 30:'MT',\n",
    "     2:'AK', 31:'NE',\n",
    "     4:'AZ', 32:'NV',\n",
    "     5:'AR', 33:'NH',\n",
    "     6:'CA', 34:'NJ',\n",
    "     8:'CO', 35:'NM',\n",
    "     9:'CT', 36:'NY',\n",
    "    10:'DE', 37:'NC',\n",
    "    11:'DC', 38:'ND',\n",
    "    12:'FL', 39:'OH',\n",
    "    13:'GA', 40:'OK',\n",
    "    15:'HI', 41:'OR',\n",
    "    16:'ID', 42:'PA',\n",
    "    17:'IL', 44:'RI',\n",
    "    18:'IN', 45:'SC',\n",
    "    19:'IA', 46:'SD',\n",
    "    20:'KS', 47:'TN',\n",
    "    21:'KY', 48:'TX',\n",
    "    22:'LA', 49:'UT',\n",
    "    23:'ME', 50:'VT',\n",
    "    24:'MD', 51:'VA',\n",
    "    25:'MA', 53:'WA',\n",
    "    26:'MI', 54:'WV',\n",
    "    27:'MN', 55:'WI',\n",
    "    28:'MS', 56:'WY',\n",
    "    29:'MO' } )   \n",
    "    \n",
    "    \n",
    "    ## Labor Force Recode\n",
    "    x = df['pemlr'].value_counts().sort_index()\n",
    "    ###print(x)\n",
    "\n",
    "    df['laborforce_employed'] = df['pemlr'].isin([1,2])\n",
    "    df['laborforce_unemployed'] = df['pemlr'].isin([3,4])\n",
    "    df['laborforce_nopart'] = df['pemlr'].isin([5,6,7])\n",
    "\n",
    "    ## Family Income Brackets\n",
    "    x = df['hefaminc'].value_counts().sort_index()\n",
    "    ###print(x.cumsum() / x.sum() )\n",
    "\n",
    "    df['hefaminc_0k_15k'] = df['hefaminc'].between(1,5)\n",
    "    df['hefaminc_15k_50k'] = df['hefaminc'].between(6,11)\n",
    "    df['hefaminc_50k_100k'] = df['hefaminc'].between(12,14)\n",
    "    df['hefaminc_100kplus'] = df['hefaminc'].between(15,99)\n",
    "\n",
    "    ## Hourly Status\n",
    "    df['peernhry'] = df['peernhry'].replace({1:1, 2:0},inplace=False)\n",
    "    ###print(df['peernhry'].value_counts().sort_index())\n",
    "\n",
    "    ## Parttime status\n",
    "    df['laborforce_no'] = (df['prwkstat']==1)\n",
    "    df['laborforce_unemp'] = df['prwkstat'].isin([11,12])\n",
    "    df['laborforce_ft'] = df['prwkstat'].isin([2,3,4,5])\n",
    "    df['laborforce_pt'] = df['prwkstat'].isin([6,7,8,9,10])\n",
    "\n",
    "    ## Marriage status\n",
    "    df['marriage'] = df['hrhtype'].isin([1,2])\n",
    "\n",
    "    ## Rent\n",
    "    df['rent'] = df['hetenure'].isin([2,3])\n",
    "\n",
    "    ## Agricultural Workers\n",
    "    df['agri'] = df['pragna'].replace({1:1, 2:0},inplace=False)\n",
    "\n",
    "\n",
    "    ## Schooling\n",
    "    x = df['peeduca'].value_counts().sort_index()\n",
    "    ###print(x.cumsum() / x.sum() )\n",
    "    df['educ_lesshs'] = df['peeduca'].isin([31,32,33,34,35,36,37,38,39])\n",
    "    df['educ_someAA'] = df['peeduca'].isin([40,41,42])\n",
    "    df['educ_BA'] = df['peeduca'].isin([43])\n",
    "    df['educ_grad'] = df['peeduca'].isin([44,45,46])\n",
    "\n",
    "    # df[['prernwa', 'puernh1c']].describe()\n",
    "    stats_list = [       'laborforce_employed', 'laborforce_unemployed', 'laborforce_nopart',\n",
    "           'hefaminc_0k_15k', 'hefaminc_15k_50k', 'hefaminc_50k_100k',\n",
    "           'hefaminc_100kplus', 'laborforce_no', 'laborforce_unemp',\n",
    "           'laborforce_ft', 'laborforce_pt', 'marriage', 'rent', 'agri',\n",
    "           'educ_lesshs', 'educ_someAA', 'educ_BA', 'educ_grad', 'prernwa']\n",
    "\n",
    "\n",
    "    ## weight denominator\n",
    "    weight_total = df.groupby(['state','hrmonth','hryear4'])['pwsswgt'].sum()\n",
    "    for s in stats_list:\n",
    "        df[s] = df[s]*df['pwsswgt']\n",
    "\n",
    "    df_final = df.groupby(['state','hrmonth','hryear4'])[stats_list].sum()\n",
    "\n",
    "\n",
    "    df_final = df_final.join(weight_total)\n",
    "    for s in stats_list:\n",
    "        df_final[s] = df_final[s].divide(df_final['pwsswgt'])\n",
    "\n",
    "    df_final_output = df_final_output.append(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97c0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_output.to_pickle('/Users/hsujulia/Documents/GitHub/causalinference_crashcourse/Notebooks/9 Synthetic Control - CPS Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc54bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
