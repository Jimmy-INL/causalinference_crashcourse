{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogenous treatment effect models\n",
    "Julian Hsu\n",
    "30 Aug 2021\n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write ML Models](#Section1)\n",
    "* [Simulator Functions](#Section2)\n",
    "* [Many Simulations](#Section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import numpy as np\n",
    "import os as os \n",
    "import scipy.stats \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import display    \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression, Lasso, LassoCV, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/hsujulia/Amazon WorkDocs Drive/My Documents/Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hsujulia/Amazon WorkDocs Drive/My Documents/Python\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error: '/Users/hsujulia/Amazon WorkDocs Drive/My Documents/Python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-70890f45e6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(os.getcwd())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mHTELibrary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_fill_cache\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/Users/hsujulia/Amazon WorkDocs Drive/My Documents/Python'"
     ]
    }
   ],
   "source": [
    "# print(os.getcwd())\n",
    "\n",
    "import HTELibrary as hte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_hte(N, hte_type):\n",
    "    '''\n",
    "    Generate data with different types of HTE forms:\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    x = np.random.uniform(0,1, N)\n",
    "    y = 10 + 2*(np.log(1+x)) + x**2 + np.random.normal(0,1,N)\n",
    "    \n",
    "    if hte_type=='constant':\n",
    "        hte = 1\n",
    "    elif hte_type=='linear':\n",
    "        hte = 2*x\n",
    "    elif hte_type=='quadratic':\n",
    "        hte = 0.5*x**2\n",
    "    elif hte_type=='piecewise':\n",
    "        hte = np.zeros_like(x)\n",
    "        hte[(x < 0.20)] = 1\n",
    "        hte[(x >=0.20) & (x < 0.80) ] = 2\n",
    "        hte[(x >=0.80) ] = 5\n",
    "    elif hte_type=='log':\n",
    "        hte = np.log(1+x*2)*1.5\n",
    "    elif hte_type=='piecewise_linear':\n",
    "        hte = np.zeros_like(x)\n",
    "        hte[(x < 0.20)] = x[(x < 0.20)]*0.1\n",
    "        hte[(x >=0.20) & (x < 0.80) ] = x[(x >=0.20) & (x < 0.80) ]*0.75\n",
    "        hte[(x >=0.80) ] = x[(x >=0.80) ]*(-0.5)\n",
    "    elif hte_type=='trig':\n",
    "        hte = np.sin(1+x*10)*x\n",
    "    else:\n",
    "        print('Choose a hte type!')\n",
    "        \n",
    "    t = ( np.exp(x) / (1+np.exp(x)) > np.random.uniform(0,1,N)).astype(float)\n",
    "    y  += t*hte\n",
    "    return pd.DataFrame(data={'x':x, 't':t, 'y':y, 'hte': hte})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 5000\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1, normalize=True, random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_dictionary = {'force_second_stage':'CVLasso'}\n",
    "n_data_splits = 5\n",
    "lasso_max_iter = 5000\n",
    "lasso_alpha = 5\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "i = 0\n",
    "for t in ['constant','linear','quadratic','piecewise','piecewise_linear']:\n",
    "\n",
    "    df = gen_data_hte(N, t)\n",
    "    \n",
    "    df['x2'] = df['x'].pow(2)\n",
    "    df['x2_ln'] = np.log(1+df['x'])    \n",
    "#     for p in range(9):\n",
    "#         df['x_'+str(p)] = ( np.round(df['x'],1)==np.round(p*0.1,1) ).astype(float)\n",
    "#         df['x_X'+str(p)] = df['x_'+str(p)]*df['x']\n",
    "    full_feature_list = [ x for x in df.columns if 'x' in x]\n",
    "\n",
    "    ## 3. Run through each combination of models\n",
    "    SGCT = hte.het_dml_approaches.SGCT(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, aux_dictionary)\n",
    "    df['dml_SGCT_TE'] = SGCT[0]\n",
    "    df['dml_SGCT_SE'] = SGCT[1]    \n",
    "    df['dml_SGCT_P'] = SGCT[2]\n",
    "    df['dml_SGCT_Y0'] = SGCT[3]        \n",
    "\n",
    "    HR = hte.het_dml_approaches.HR(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, aux_dictionary)\n",
    "    df['dml_HR_TE'] = HR[0]\n",
    "    df['dml_HR_SE'] = HR[1]    \n",
    "    df['dml_HR_P'] = HR[2]\n",
    "    df['dml_HR_Y0'] = HR[3]\n",
    "\n",
    "    dr_cvl = hte.other.DR(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, {'force_second_stage':'CVLasso'})\n",
    "    df['DR_CVL_TE'] = dr_cvl[0]\n",
    "    df['DR_CVL_SE'] = dr_cvl[1]   \n",
    "    df['DR_CVL_P'] = dr_cvl[2]\n",
    "    df['DR_CVL_Y0'] = dr_cvl[3]\n",
    "\n",
    "\n",
    "    tree_grf = hte.trees.grf(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, {'n_estimators':1000})\n",
    "    df['GRF_TE'] = tree_grf[0]\n",
    "    df['GRF_SE'] = tree_grf[1]\n",
    "    df['GRF_P'] = tree_grf[2]\n",
    "    df['GRF_Y0'] = tree_grf[3]\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10),sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].scatter(df['x'], df['dml_SGCT_TE'], label='SGCT', alpha = 0.15, color='green')\n",
    "    ax[0].scatter(df['x'], df['dml_HR_TE'], label='HR', alpha = 0.15, color='coral')\n",
    "    ax[0].scatter(df['x'], df['hte'], label='Truth', alpha = 0.25, color='royalblue')\n",
    "\n",
    "    ax[0].legend(loc='upper left', fontsize=15)\n",
    "    ax[0].grid()\n",
    "    ax[0].set_ylabel('HTE', fontsize=15)\n",
    "    ax[0].set_xlabel('x', fontsize=15)\n",
    "    \n",
    "    ax[1].scatter(df['x'], df['DR_CVL_TE'], label='DoublyRobust', alpha = 0.15, color='purple')\n",
    "    ax[1].scatter(df['x'], df['GRF_TE'], label='GRF', alpha = 0.15, color='pink')\n",
    "    ax[1].scatter(df['x'], df['hte'], label='Truth', alpha = 0.25, color='royalblue')\n",
    "    \n",
    "    ax[1].legend(loc='upper left', fontsize=15)\n",
    "    ax[1].grid()\n",
    "    ax[1].set_ylabel('HTE', fontsize=15)\n",
    "    ax[1].set_xlabel('x', fontsize=15)\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0)\n",
    "    fig.suptitle('Performance when Functional Form is {0}'.format(i), fontsize=15) \n",
    "    fig.patch.set_facecolor('white')\n",
    "    fig.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "i = 0\n",
    "for t in ['constant','linear','quadratic','piecewise','piecewise_linear']:\n",
    "\n",
    "    df = gen_data_hte(N, t)\n",
    "    \n",
    "    df['x2'] = df['x'].pow(2)\n",
    "    df['x2_ln'] = np.log(1+df['x'])\n",
    "    for p in range(9):\n",
    "        df['x_'+str(p)] = ( np.round(df['x'],1)==np.round(p*0.1,1) ).astype(float)\n",
    "        df['x_X'+str(p)] = df['x_'+str(p)]*df['x']\n",
    "    full_feature_list = [ x for x in df.columns if 'x' in x]\n",
    "\n",
    "    ## 3. Run through each combination of models\n",
    "    SGCT = hte.het_dml_approaches.SGCT(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, aux_dictionary)\n",
    "    df['dml_SGCT_TE'] = SGCT[0]\n",
    "    df['dml_SGCT_SE'] = SGCT[1]    \n",
    "    df['dml_SGCT_P'] = SGCT[2]\n",
    "    df['dml_SGCT_Y0'] = SGCT[3]        \n",
    "\n",
    "    HR = hte.het_dml_approaches.HR(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, aux_dictionary)\n",
    "    df['dml_HR_TE'] = HR[0]\n",
    "    df['dml_HR_SE'] = HR[1]    \n",
    "    df['dml_HR_P'] = HR[2]\n",
    "    df['dml_HR_Y0'] = HR[3]\n",
    "\n",
    "    dr_cvl = hte.other.DR(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, {'force_second_stage':'CVLasso'})\n",
    "    df['DR_CVL_TE'] = dr_cvl[0]\n",
    "    df['DR_CVL_SE'] = dr_cvl[1]   \n",
    "    df['DR_CVL_P'] = dr_cvl[2]\n",
    "    df['DR_CVL_Y0'] = dr_cvl[3]\n",
    "\n",
    "\n",
    "    tree_grf = hte.trees.grf(df, \n",
    "                    full_feature_list, 'y', 't',\n",
    "                    full_feature_list,\n",
    "                    y_models['ols'], t_models['logit'],\n",
    "                   n_data_splits, {'n_estimators':1000})\n",
    "    df['GRF_TE'] = tree_grf[0]\n",
    "    df['GRF_SE'] = tree_grf[1]\n",
    "    df['GRF_P'] = tree_grf[2]\n",
    "    df['GRF_Y0'] = tree_grf[3]\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10),sharex=True, sharey=True)\n",
    "\n",
    "    ax[0].scatter(df['x'], df['dml_SGCT_TE'], label='SGCT', alpha = 0.15, color='green')\n",
    "    ax[0].scatter(df['x'], df['dml_HR_TE'], label='HR', alpha = 0.15, color='coral')\n",
    "    ax[0].scatter(df['x'], df['hte'], label='Truth', alpha = 0.50, color='royalblue')\n",
    "\n",
    "    ax[0].legend(loc='upper left', fontsize=20)\n",
    "    ax[0].grid()\n",
    "    ax[0].set_ylabel('HTE', fontsize=20)\n",
    "    ax[0].set_xlabel('x', fontsize=20)\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    ax[1].scatter(df['x'], df['DR_CVL_TE'], label='Proxy', alpha = 0.15, color='purple')\n",
    "    ax[1].scatter(df['x'], df['GRF_TE'], label='GRF', alpha = 0.25, color='pink')\n",
    "    ax[1].scatter(df['x'], df['hte'], label='Truth', alpha = 0.50, color='royalblue')\n",
    "    \n",
    "    ax[1].legend(loc='upper left', fontsize=20)\n",
    "    ax[1].grid()\n",
    "    ax[1].set_ylabel('HTE', fontsize=20)\n",
    "    ax[1].set_xlabel('x', fontsize=20)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0)\n",
    "    fig.suptitle('Performance when Functional Form is {0}'.format(i), fontsize=20) \n",
    "    fig.patch.set_facecolor('white')\n",
    "    fig.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
