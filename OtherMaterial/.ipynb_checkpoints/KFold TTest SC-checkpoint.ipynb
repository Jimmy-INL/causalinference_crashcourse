{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1fac0f",
   "metadata": {},
   "source": [
    "# Synthetic Control Bias and Correction with K-Folds\n",
    "Julian Hsu\n",
    "19 Oct 2022\n",
    "\n",
    "This notebook find the bias in standard SC models, and implements the K-Fold procedure from  [Chernozhukov, Wuthrich, and Zhu (2022)](https://arxiv.org/pdf/1812.10820.pdf)  to correct this.\n",
    "\n",
    "### Table of Contents\n",
    "1. K-Fold SC Procedure Overview\n",
    "2. Class of Functions for DGP and SC\n",
    "3. Simulation of Bias\n",
    "4. Implementation of K-Fold SC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707a1ca",
   "metadata": {},
   "source": [
    "## K-Fold SC Procedure Overview\n",
    "This comes from the [Chernozhukov, Wuthrich, and Zhu (2022)](https://arxiv.org/pdf/1812.10820.pdf) paper about using a generalized K-fold procedure to estimate an SC model and do inference.\n",
    "\n",
    "We first divide the panel data of pre-treatment data into $K$ consecutive time periods where each block (or fold) is $H_k$ periods. Where $H_k$ has the length $r = min\\{ \\frac{T_0}{K}, T_1 \\}$ . $T_0$ is the number of pre-treatment periods and $T_1$ is the number of post-treatment periods. We then run a SC model on each block (or fold) and use it to estimate the counterfactual on all other blocks. That is, for $k=1,...,K$ we estimate a different ATET:\n",
    "\n",
    "$$\\hat{\\tau}_k = \\dfrac{1}{T_1} \\sum^T_{t=T_0+1} \\big( Y_{0t} - \\sum^N_{i=1} \\hat{\\omega_{i,(k)}} Y_{it} \\big) - \\dfrac{1}{|H_k|}\\sum_{t \\in H_k} \\big( Y_{0t} - \\sum^N_{i=1} \\hat{\\omega_{i,(k)}} Y_{it} \\big) $$\n",
    "$$\\hat{\\tau} = \\dfrac{1}{K}\\sum^K_{k=1} \\hat{\\tau}_k$$\n",
    "Where $\\hat{\\omega_{i,(k)}} $ is obtained by training the SC model on the data not in block $k$.\n",
    "\n",
    "Note that the first summation is the standard SC model with the observed treated's post-treatment outcome $Y_{0t}$ minus the estimated counterfactual based on the estimated weights applied to the controls' post-treatment outcome. The risk is that this paper shows the estimator is biased, and can be corrected by doing the same comparison by for the *pre-treatment* periods.\n",
    "\n",
    "Where does this bias come from? If the data is high-dimensional by having a lot of time periods $T_0 >> N$, then you can have an error from estimation. \n",
    "\n",
    "This K-fold model also offers standard errors that do not depend on a Long-Run Variance (LRV). The t-statistic of K-fold model estimator is:\n",
    "\n",
    "$$\\mathbb{T}_K = \\dfrac{\\sqrt{K}(\\hat{\\tau} - \\tau_0 )}{ \\hat{\\sigma}_{\\hat{k}} }$$\n",
    "$$\\text{  where  } \\hat{\\sigma}_{\\hat{k}} = \\sqrt{1 + \\frac{K \\cdot r}{T_1}} \\sqrt{\\frac{1}{K-1} \\sum^K_{k=1}(\\hat{\\tau}_k  -\\hat{\\tau} )^2   }   $$\n",
    "\n",
    "From here, we can construct a $(1-\\alpha)$ confidence interval:\n",
    "\n",
    "$$CI_K(1-\\alpha) = \\hat{\\tau} \\mp \\mathbb{cv}(1-\\alpha/2) \\cdot \\frac{\\hat{\\sigma}_k}{\\sqrt{K}}  $$\n",
    "where $\\mathbb{cv}(1-\\alpha/2)$ is the $(1-\\alpha/2)$-th quantile of the t distribution with $K-1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e59f0",
   "metadata": {},
   "source": [
    "## Class of Functions for DGP and SC\n",
    "### DGP\n",
    "We will have a function, `panel_station` which outputs multiple types of outcomes following [Chernozhukov et al.'s $\\tau$-test SC paper, (2018)](https://arxiv.org/abs/1812.10820).\n",
    "\n",
    "Stationary Trend:\n",
    "$$Y_{it} = \\lambda_i f_t + \\eta_{it} $$\n",
    "Non-Stationary Trend with a random walk:\n",
    "$$Y_{it} = \\theta_{t} +  \\lambda_i f_t + \\eta_{it} $$\n",
    "Non-Stationary Trend with a random walk and sparse deviation:\n",
    "$$Y_{it} = \\theta_{1t} + 1\\{i=1\\}\\theta_{2t}  \\lambda_i f_t + \\eta_{it} $$\n",
    "Heterogeneous Trends:\n",
    "$$Y_{it} = \\theta_{it} +  \\lambda_i f_t + \\eta_{it} $$\n",
    "\n",
    "where\n",
    "$$\\eta_{it} = \\rho_i \\eta_{it-1} + \\epsilon_{it}, \\epsilon_{it} \\sim N(0,\\sigma^2_\\epsilon) $$\n",
    "$$f_t \\sim N(0, \\sigma^2_f) $$\n",
    "$$\\theta_t = \\theta_{t-1} + \\xi_t , \\xi_t \\sim N(0,1)$$\n",
    "$$\\theta_{1t} = \\theta_{1t-1} + \\xi_{1t}, \\xi_{1t} \\sim N(0,1) $$\n",
    "$$\\theta_{2t} = \\theta_{2t-1} + \\xi_{2t}, \\xi_{1t} \\sim N(0,1) $$\n",
    "$$\\theta_{it} = i + i \\cdot t$$\n",
    "### SC Models\n",
    "For simplicity, focus on the Abadie, Diamond, Hainmueller (2010) SC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c7f0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "322f8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dgp:    \n",
    "    def panel_station(seed_number = 2739,\n",
    "                     pre_time_units = 20,\n",
    "                     pst_time_units = 5,\n",
    "                     x_units_control = 15,\n",
    "                     x_units_treat = 5,                      \n",
    "                     K_dim = 5,\n",
    "                     at = 2):\n",
    "        '''\n",
    "        seed_number  random_number_set\n",
    "        pre_time_units   how many pre-treatment time periods?\n",
    "        pst_time_units   how many post-treatment time periods?\n",
    "        x_units      how many units?\n",
    "        K_dim        how many covariates (assume uniform)\n",
    "        at           ATET estimate\n",
    "        '''  \n",
    "        xfun = np.random.RandomState(seed_number)\n",
    "        time_units = pre_time_units + pst_time_units\n",
    "        t_range = pd.date_range(pd.to_datetime('2020/01/01'), periods=time_units, freq=\"M\")\n",
    "        x_units = x_units_control+x_units_treat\n",
    "        u_range = range(x_units)\n",
    "        sigma_epsilon = 1\n",
    "        rho = 0.75\n",
    "\n",
    "\n",
    "        df_return = pd.DataFrame(index=list(u_range)*time_units, \n",
    "                     columns=['date'],\n",
    "                     data= np.array( [ [p]*x_units for p in t_range] ).flatten() )\n",
    "        df_return.reset_index(names='unitid', inplace=True)\n",
    "\n",
    "        df_return.sort_values(by=['unitid','date'], ascending=True, inplace=True)\n",
    "        df_return['_f'] = np.log( 1+df_return.groupby('unitid').rank() )\n",
    "\n",
    "        ## Lambda is time-invariant\n",
    "        df_return['_lambda'] = xfun.uniform(0,1, len(df_return) )\n",
    "        df_return['_lambda'] = df_return.groupby('unitid')['_lambda'].mean()\n",
    "        df_return['_lambda'] = df_return['_lambda'].fillna(df_return.groupby('unitid')['_lambda'].transform('mean'))\n",
    "\n",
    "        ## eta is lagged\n",
    "        df_return['_eta'] = xfun.normal(0, sigma_epsilon, len(df_return))\n",
    "        df_return['_eta'] = df_return.groupby('unitid').shift(1)['_eta'].fillna(0)*rho + df_return['_eta']\n",
    "\n",
    "        ## xi is unit-invariant\n",
    "        ## create unit-invariant AR values\n",
    "        def ar1(error_name, theta_name):\n",
    "            df_return[error_name] = xfun.normal(0, 1, len(df_return))\n",
    "            df_return[error_name] = df_return.groupby('unitid')[error_name].mean()\n",
    "            df_return[error_name] = df_return[error_name].fillna(df_return.groupby('unitid')[error_name].transform('mean'))\n",
    "            df_return[theta_name] = df_return.groupby('unitid').shift(1)[error_name].fillna(0)*rho + df_return[error_name]\n",
    "        ar1('_xi', '_theta_t')    \n",
    "        ar1('_xi1', '_theta_t1')    \n",
    "        ar1('_xi2', '_theta_t2')    \n",
    "\n",
    "        ## Allow _theta_t2 to be sparse\n",
    "        ## It is allowed to be non-zero for only one unit\n",
    "        random_unit = xfun.choice(x_units,1)[0]\n",
    "        df_return.loc[df_return['unitid']!=random_unit, '_theta_t2'] = 0\n",
    "\n",
    "        ## heterogeneous trends\n",
    "        df_return['_theta_it'] = (df_return['unitid']+1) + np.log(df_return['unitid']+1)*df_return['_f']\n",
    "        ## Assign treatment status\n",
    "        df_return['treated_unit'] = (df_return['unitid'].isin(np.arange(x_units_treat))).astype(float)\n",
    "        df_return['post'] = (df_return['date'].isin(t_range[-1*pst_time_units:])).astype(float)\n",
    "        df_return['W'] =     df_return['treated_unit']*    df_return['post']\n",
    "        ## Assign outcome ot treated values\n",
    "        df_return['y_station']      = df_return['W']*at + df_return['_lambda'] * df_return['_f'] + df_return['_eta']\n",
    "        df_return['y_nonstation_rw']= df_return['W']*at + df_return['y_station'] + df_return['_theta_t']\n",
    "        df_return['y_nonstation_rw_sparse'] = df_return['W']*at + df_return['y_station'] + df_return['_theta_t1'] + df_return['_theta_t2']\n",
    "        df_return['y_nonstation_het']       = df_return['W']*at + df_return['y_station'] + df_return['_theta_it']\n",
    "        \n",
    "        df_return['unitid'] = df_return['unitid'].apply(str)        \n",
    "        return df_return\n",
    "    \n",
    "    def clean_and_input_data(dataset=None, \n",
    "                             treatment='treated_unit', \n",
    "                             date='T',\n",
    "                             post='post', outcome='Y'):\n",
    "        \n",
    "        C_pre = dataset.loc[(dataset[treatment]==0) & (dataset[post]==0)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        C_pst = dataset.loc[(dataset[treatment]==0) & (dataset[post]==1)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pre = dataset.loc[(dataset[treatment]==1) & (dataset[post]==0)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pst = dataset.loc[(dataset[treatment]==1) & (dataset[post]==1)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        return {'C_pre':C_pre, 'C_pst':C_pst, 'T_pre':T_pre, 'T_pst':T_pst}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a42ae467",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Also code up the ADH weights\n",
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class adh:\n",
    "    ## Define loss function\n",
    "    def loss_w(W, X, y) -> float:\n",
    "        return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "    def get_w(X, y):\n",
    "        ## Initialize at sample average with some noise\n",
    "        w_start = [1/X.shape[1]]*X.shape[1]+np.random.uniform(-0.005,0.005, X.shape[1])\n",
    "    #     w_start = np.ones(X.shape[1])\n",
    "\n",
    "        weights = fmin_slsqp(partial(adh.loss_w, X=X, y=y),\n",
    "                             np.array(w_start),\n",
    "                             f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                             iter=50000, \n",
    "                             bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                             disp=False)\n",
    "        return weights   \n",
    "    \n",
    "    def predict_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        for t in treatment_pre.columns:\n",
    "            t_dict = adh.get_w(control_holdout,treatment_holdout[t])\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict.T)\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict.T)\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['omega'].append(t_dict)\n",
    "            holdout_dict['weights'].append(t_dict)\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)\n",
    "\n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "        \n",
    "        return holdout_dict    \n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:] - output_df[c+'_est'][treatment_periods:]\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c642d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad578b3a",
   "metadata": {},
   "source": [
    "## Simulation of Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings ={'atet_gt': 5,\n",
    "          'T0':20,\n",
    "          'N':15}\n",
    "df_sim = pd.DataFrame()\n",
    "y_outcome = ['y_station', 'y_nonstation_rw']\n",
    "#              , 'y_nonstation_rw_sparse',\n",
    "#        'y_nonstation_het']\n",
    "adh_estimates = []\n",
    "sim_range = range(500)\n",
    "t0_range = [5,20,100]\n",
    "for t0 in t0_range:\n",
    "    for sim in sim_range:\n",
    "        df = dgp.panel_station(seed_number=sim,\n",
    "                         pre_time_units=t0,\n",
    "                         pst_time_units=5,\n",
    "                         x_units_control = settings['N'],\n",
    "                         x_units_treat = 1,\n",
    "                         K_dim = 3,\n",
    "                         at=settings['atet_gt'])\n",
    "        for y_iter in y_outcome:\n",
    "            ## Clean data\n",
    "            di_dict = dgp.clean_and_input_data(dataset=df,\n",
    "                                               treatment='treated_unit', \n",
    "                                               date='date',\n",
    "                                               post='post',\n",
    "                                              outcome=y_iter)\n",
    "\n",
    "            ## Create Primitives\n",
    "            tw =  len(df.loc[ df['W']==1]['date'].unique())\n",
    "            treatment_window = len(df.loc[(df['W']==0)]['date'].unique())-tw, tw\n",
    "\n",
    "            time_list = np.arange( np.sum(treatment_window) )\n",
    "            T_len = len(time_list)\n",
    "\n",
    "            ## Time block permutations\n",
    "            permutations_subset_block = []\n",
    "\n",
    "            for i in range(T_len):\n",
    "                half_A = time_list[-1*(T_len-i):]\n",
    "                half_B = time_list[0:i]\n",
    "                scrambled_list = np.concatenate([half_A, half_B]) \n",
    "                permutations_subset_block.append( list(scrambled_list)  )\n",
    "\n",
    "            treatment_window_pre_treatment = [int(treatment_window[0]*0.75) ,treatment_window[0]-int(treatment_window[0]*0.75)   ]\n",
    "\n",
    "            ## Run ADH Model\n",
    "            ao3 = adh.predict_omega(di_dict['T_pre'], di_dict['C_pre'], treatment_window_pre_treatment)\n",
    "            adh_output = adh.sc_style_results(di_dict['T_pre'], di_dict['T_pst'],\n",
    "                                di_dict['C_pre'], di_dict['C_pst'],\n",
    "                                np.zeros(di_dict['T_pst'].shape[1]), np.array(ao3['omega']))\n",
    "            sim_est=  adh_output['atet'].mean(axis=0).values[0]   \n",
    "            row = pd.DataFrame(index=[sim], data={'atet':sim_est,\n",
    "                                   'gt':settings['atet_gt'],\n",
    "                                   'T0':t0,\n",
    "                                                  'y':y_iter,\n",
    "                                   'N':settings['N']})\n",
    "            df_sim = pd.concat([df_sim, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=len(y_outcome),ncols=1, figsize=(20,10))\n",
    "for y_i, y_iter in zip(range(len(y_outcome)), y_outcome):\n",
    "    for t0 in t0_range:\n",
    "        if t0==5:\n",
    "            color='red'\n",
    "        elif t0==10:\n",
    "            color='royalblue'\n",
    "        else:\n",
    "            color='seagreen'\n",
    "        a = ax[y_i].hist(df_sim.loc[(df_sim['T0']==t0) & (df_sim['y']==y_iter)]['atet'], \n",
    "                    density=True, alpha=0.25, color=color,\n",
    "                   label='T0={0}'.format(t0))\n",
    "        df_sim.loc[(df_sim['T0']==t0) & (df_sim['y']==y_iter)]['atet'].plot(kind='density',\n",
    "                                                                            ax=ax[y_i],\n",
    "                                                                            label='T0={0}, Density'.format(t0),\n",
    "                                                                           color=color)\n",
    "        ax[y_i].vlines(x= settings['atet_gt'], \n",
    "                       color='black',\n",
    "                  ymin=0, ymax=a[0].max(),\n",
    "                  linewidth=5)\n",
    "    ax[y_i].legend(title='T0 with \\nN={0} Control Units'.format(settings['N']))\n",
    "    ax[y_i].set_title('Outcome = {0}'.format(y_iter))\n",
    "    ax[y_i].grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d61a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of K-Fold SC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
