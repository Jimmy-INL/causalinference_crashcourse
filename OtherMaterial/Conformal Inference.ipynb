{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c84a42",
   "metadata": {},
   "source": [
    "# Conformal Inference\n",
    "Julian Hsu\n",
    "5jun2022\n",
    "\n",
    "In this notebook we look at the idea of conformal inference from *Chernozhukov, Wuthrich, and Zhu* : https://arxiv.org/abs/1712.09089. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67dfdbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hsujulia/Documents/GitHub/causalinference_crashcourse/OtherMaterial\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "print (os.getcwd() )\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import scipy\n",
    "import functools\n",
    "import sklearn as sk\n",
    "from sklearn import impute, pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07bac965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_settings = {'time units': 10,\n",
    "                'x_units':30,\n",
    "                 'K_dim':10,\n",
    "                'treatment': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbfb1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to automatically give us a panel dataset\n",
    "def synth_panel(seed_number = 2123, \n",
    "                time_units = 10, \n",
    "                x_units = 30, \n",
    "                K_dim = 5,\n",
    "               treatment_type = 'both',\n",
    "               treatment_imp = 10,\n",
    "               treatment_het = False):\n",
    "    '''\n",
    "    seed_number  random_number_set\n",
    "    time_units   how many time periods?\n",
    "    x_units      how many units?\n",
    "    K_dim        how many covariates (assume uniform)\n",
    "    treatment_type    how is treatment determined? {'X','Y', 'both'}\n",
    "    treatment_imp     the level of treatment effect, constant for all post-treatment times\n",
    "    '''\n",
    "    ## Set the seed for random number\n",
    "    xfun = np.random.RandomState(seed_number)\n",
    "    \n",
    "    ## Construct covariates, time-invariant fixed effects, and first period outcome\n",
    "    X = xfun.uniform(low=0, high=1, size= (x_units, K_dim) )\n",
    "    X_coef = xfun.uniform(low=-2, high=2, size = K_dim)\n",
    "    x_list = ['x'+str(k) for k in range(K_dim)]\n",
    "    \n",
    "    \n",
    "    fe = xfun.normal(0,1, size=x_units)\n",
    "    \n",
    "    output_df = pd.DataFrame(data=X, columns=x_list)\n",
    "    output_df['fe'] = fe\n",
    "    output_df['Y'] = np.dot(X,X_coef) + fe + xfun.normal(0,1, size=x_units)\n",
    "    output_df['T'] = pd.to_datetime('2020/01/01')\n",
    "    output_df['unitid'] =  np.arange(x_units).astype(int)\n",
    "\n",
    "    decay = 0.60\n",
    "\n",
    "    for t in range(1,time_units):    \n",
    "        ## Create the panel by setting up an AR(1) type function.\n",
    "        prev_date = (pd.to_datetime('2020/01/01')+pd.offsets.DateOffset(months=t-1))\n",
    "        prev_data = decay*( output_df.loc[(output_df['T']==prev_date)][[r for r in output_df.columns if 'x' in r ]]     )\n",
    "        ## perturb it a little with AR(1)\n",
    "        prev_data += xfun.normal(0,1, size=(x_units,K_dim))\n",
    "        prev_data['Y'] = decay*np.dot(prev_data,X_coef) + fe + xfun.normal(0,1, size=x_units)\n",
    "        prev_data['T'] = pd.to_datetime('2020/01/01') + pd.offsets.DateOffset(months=t)\n",
    "        prev_data['unitid'] = np.arange(x_units).astype(int)\n",
    "        output_df = pd.concat([ output_df, prev_data])\n",
    "    output_df['unitid'] = 'unit' + output_df['unitid'].apply(str)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Decide the treatment effect based either the (i) covariates, (ii) pre-trend outcome, or (iii) both.\n",
    "    \n",
    "    Assign treatment to happen at the third to last time period\n",
    "    '''\n",
    "    if treatment_type=='X':\n",
    "        input_treatment = x_list[:]\n",
    "    elif treatment_type=='Y':\n",
    "        input_treatment = 'Y'\n",
    "    else:\n",
    "        input_treatment = x_list[:] + ['Y']\n",
    "        \n",
    "    output_df['treatment_latent'] = 0\n",
    "    treatment_date = (pd.to_datetime('2020/01/01')+pd.offsets.DateOffset(months=time_units-2))    \n",
    "    \n",
    "    latent_treatment = np.dot(output_df[input_treatment], \n",
    "                              xfun.uniform(-4,4, size=len(input_treatment))) +\\\n",
    "                             xfun.normal(0,1,size=len(output_df))\n",
    "    output_df['treatment_latent'] = np.exp(latent_treatment) / (1+ np.exp(latent_treatment))\n",
    "    \n",
    "    ## First decide treatment in the treatment time, and then make it permanent.    \n",
    "    treatment_latent_xsection = output_df.loc[(output_df['T'] == treatment_date)][['unitid','treatment_latent']]\n",
    "    treatment_decision = (treatment_latent_xsection['treatment_latent'] >\\\n",
    "                          treatment_latent_xsection['treatment_latent'].quantile(q=0.75))\n",
    "    treatment_ids = treatment_latent_xsection.loc[(treatment_decision==True)]['unitid']\n",
    "    \n",
    "    output_df['post'] = (output_df['T'] >= treatment_date).astype(float)\n",
    "    output_df['treatment_units'] = (output_df['unitid'].isin(treatment_ids)).astype(float)\n",
    "    \n",
    "    output_df['treatment'] = 0\n",
    "    output_df.loc[ (output_df['unitid'].isin(treatment_ids)) & (output_df['T'] >= treatment_date), 'treatment'  ] = 1\n",
    "\n",
    "    '''\n",
    "    Apply treatment effect. \n",
    "    if we allow treatment heterogeneity, assign treatment such that the ATE!=ATET\n",
    "    '''\n",
    "    if treatment_het==False:\n",
    "        output_df['treatment_GT']  = treatment_imp\n",
    "    else:\n",
    "        ## Calculate the proportion treated\n",
    "        treat_mean = output_df['treatment'].mean()\n",
    "        output_df['treatment_GT'] = treatment_imp/2\n",
    "        output_df.loc[(output_df['treatment']==1), 'treatment_GT'] = treatment_imp*2\n",
    "\n",
    "        \n",
    "    output_df.loc[( output_df['treatment']==1) , 'Y'] = output_df.loc[( output_df['treatment']==1)]['treatment_GT'] + output_df.loc[( output_df['treatment']==1)]['Y']\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a50d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "268db598",
   "metadata": {},
   "source": [
    "## Permutations to get P-Values\n",
    "Implement the $iid$ permutation approach. Given a set of time period, go through different iterations in that time period. \n",
    "\n",
    "Our setup is for the number pre-treatment periods $T_0$ and the number of post-treatment periods $T_1$. $\\hat{u}_t$ is the difference between the estimated proxy outcome and realized outcome.\n",
    "$$S_q(\\hat{u}) = (T_1^{-1/2}  \\sum^T_{t = T_0 + 1}|\\hat{u}_t|^q )^{1/q}$$\n",
    "**Note that $S_q(\\hat{u})$ is calculated without any permutations or scrambling of the data.** In order to get p-values, we need to do multiple permutations, each with their own instance of $S_q(\\hat{u})$. Denote each of the permutations $\\pi \\in \\Pi$ as $S_q(\\hat{u}_{\\pi})$. The p-value is then:\n",
    "\n",
    "$$\\hat{p} = 1 - \\dfrac{1}{\\Pi} \\sum_{\\pi \\in \\Pi} 1\\{ S_q(\\hat{u}_{\\pi}) < S_q(\\hat{u})  \\} $$\n",
    "\n",
    "We can also calculate the confidence interval by a grid search process. Consider a lot of different treatment effects - for example if you are interested in treatment effects that are constant in all post-treatment periods, it is just one number. Each treatment effect is a \"null hypotheses\" you incorporate when training the model, so you can calculate $\\hat{p}$ by seeing whether it is different from that treatment effect \"null hypothesis.\" Then estimate the confidence interval of $1-\\alpha$ (or set, since we are doing a grid search) where those $\\hat{p}$ are greater than tha False Positive Rate $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7bf874",
   "metadata": {},
   "source": [
    "Therefore, our implementation algorithm is:\n",
    "1. Don't scramble anything and train the model.\n",
    "    1. Estimate the treatment effect.\n",
    "    2. Estimate the residual and calculate $S_q(\\hat{u})$.\n",
    "    \n",
    "2. Estimate the counterfactual for all time periods.\n",
    "3. Pick one way of scrambling the time periods, $\\pi$;\n",
    "4. Using the model estimated before, calculate $S_q(\\hat{u}_\\pi)$. \n",
    "    1. This follows from footnote 7 from the paper:\n",
    "    \n",
    "> If the estimator of $P^N_t$ is invariant under permutations of the data ${Z_t}$ across the time series dimension (which is the case for many estimators in Section 2.3), permuting the residuals ${u^t}$ is equivalent to permuting the data ${Z_t}$.\n",
    "\n",
    "\n",
    "5. Calculate the p-value, $\\hat{p}$.\n",
    "6. If we are interested, calculate the confidence set by doing a grid search as described above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5157d",
   "metadata": {},
   "source": [
    "**But what about confidence intervals?** We use Algorithm 1. in the paper, which calculates the p-value over a lot of hypothetical treatment effect values.\n",
    "1. Choose a bunch of candidate values $\\Theta = (\\theta_1, \\theta_2, ..., \\theta_G)$\n",
    "2. For each of the $\\theta_g$ values, calculate the p-value of whether the difference between the estimated effect and $\\theta_g$ is different from zero. In other words, $H_0: \\theta = \\theta_g$. This computes the p-value following the above section, yielding $p(\\theta_g)$. This yields a p-value for each corresponding element of $\\Theta$.\n",
    "3. The confidence interval for $1 - \\alpha$ is the proportion of elements in $\\Theta$ with corresponding $p(\\theta_g) > \\alpha$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fae57",
   "metadata": {},
   "source": [
    "## Implementation for Synthetic control\n",
    "For simplicity sake, let's just use synthetic control following Abadie, Diamond, and Hainmueller (2010), which does an unpenalized synthetic control (SC) model. We can later on incorporate difference-in-difference (DiD) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "846d2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "## Define loss function\n",
    "def loss_w(W, X, y) -> float:\n",
    "    return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "def get_w(X, y):\n",
    "    ## Initialize at sample average with some noise\n",
    "    w_start = [1/X.shape[1]]*X.shape[1]+np.random.uniform(-0.005,0.005, X.shape[1])\n",
    "#     w_start = np.ones(X.shape[1])\n",
    "\n",
    "    weights = fmin_slsqp(partial(loss_w, X=X, y=y),\n",
    "                         np.array(w_start),\n",
    "                         f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                         iter=50000, \n",
    "                         bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                         disp=False)\n",
    "    return weights\n",
    "\n",
    "def syncontrol(X1=None,X0=None,\n",
    "               Y1=None,Y0=None,\n",
    "              scaledown = None):\n",
    "    '''\n",
    "    X1   observed control post-treatment\n",
    "    X0   observed control pre-treatment\n",
    "    Y1   observed treatment post-treatment\n",
    "    Y0   observed treatment pre-treatment\n",
    "    scaledown   whether to divide everything by a number, defaulted to none\n",
    "    '''\n",
    "    \n",
    "    if scaledown is None:\n",
    "        adh_weights = get_w(X0, Y0)\n",
    "    else:\n",
    "        adh_weights = get_w(X0/scaledown, Y0/scaledown)\n",
    "    ## Output the weights\n",
    "    \n",
    "    ## Output the counterfactual control outcomes:\n",
    "    ## outcome of control units before and after treatment\n",
    "    Y_hatpre = np.dot(X0,adh_weights)\n",
    "    Y_hatpst = np.dot(X1,adh_weights)\n",
    "    \n",
    "    ## Output the average treatment effect on treated\n",
    "    atet = np.average(Y1 - Y_hatpst)\n",
    "    \n",
    "    return {'weights': adh_weights, 'control_pre': Y_hatpre,\n",
    "            'control_pst': Y_hatpst, 'atet': atet} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e002cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_data_from_synth(df):    \n",
    "    df_pt = df[['unitid','T','Y']].pivot_table(columns='unitid', index='T', values='Y')\n",
    "    df_pt.reset_index(inplace=True)\n",
    "    treatment_time = df.loc[df['treatment']==1]['T'].min()\n",
    "    treated_units = df.loc[(df['treatment_units']==1)]['unitid'].unique()\n",
    "    control_pre = df_pt.loc[(df_pt['T']< treatment_time)][[e for e in df_pt.columns if e not in treated_units]]\n",
    "    control_pst = df_pt.loc[(df_pt['T']>=treatment_time)][[e for e in df_pt.columns if e not in treated_units]]\n",
    "\n",
    "    treat_pre = df_pt.loc[(df_pt['T']< treatment_time)][treated_units[0]]\n",
    "    treat_pst = df_pt.loc[(df_pt['T']>=treatment_time)][treated_units[0]]\n",
    "    return control_pre, control_pst, treat_pre, treat_pst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dafb865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conformal_inf:\n",
    "    def scrambled_residual(counterfactual, actual, \n",
    "                       scrambled_order,\n",
    "                      treatment_window):\n",
    "        '''\n",
    "        counterfactual   array of counterfactual estimates that are assumed to be ordered sequentially\n",
    "        actual           ``'' for actual values\n",
    "        scrambled_order  integer array that tells me how to scramble these\n",
    "        treatment_window list of two integers for the number of pre-treatment and post-treatment units\n",
    "        '''\n",
    "        counterfactual_ = counterfactual[scrambled_order][-1*treatment_window[1]:]\n",
    "        actual_         = actual[scrambled_order][-1*treatment_window[1]:]    \n",
    "        return actual_ - counterfactual_\n",
    "    \n",
    "    def test_statS(q, treatment_window, residual):\n",
    "        normed = np.sum(  np.power(np.abs(residual), q)  )\n",
    "        return np.power( treatment_window[1]**(-0.5)*normed , 1/q)    \n",
    "\n",
    "    def pvalue_calc(counterfactual=None,\n",
    "                    actual=None, \n",
    "                    permutation_list=None,\n",
    "                   treatment_window=None,\n",
    "                   h0 = 0):\n",
    "        control_pst = counterfactual[-1*treatment_window[1]:]\n",
    "        actual_pst  = actual[-1*treatment_window[1]:] + h0\n",
    "        control_pre = counterfactual[treatment_window[0]:treatment_window[1]:]\n",
    "        actual_pre  = actual[treatment_window[0]:treatment_window[1]:]\n",
    "        ## Calculate the residual\n",
    "        residual_initial = (actual_pst - control_pst) \n",
    "        S_q = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "\n",
    "        ## Now do a whole bunch of treatment time scrambles\n",
    "        ## We're going to permute over all time-based permutations\n",
    "        ## Adjust the actual by the null hypothesis \n",
    "        actual_temp = actual[:]\n",
    "        actual_temp[-1*treatment_window[1:]] += h0\n",
    "        S_q_pi = []\n",
    "        for r in permutation_list:\n",
    "            scrambled_dates = np.array(list(r))\n",
    "\n",
    "            residual = conformal_inf.scrambled_residual( counterfactual,\n",
    "                               actual_temp,\n",
    "                               scrambled_dates,\n",
    "                               treatment_window)    \n",
    "            S_q_pi.append(  conformal_inf.test_statS(1, treatment_window, residual - h0)  )\n",
    "        p_value = 1 - np.average( (S_q_pi < S_q) )\n",
    "        return p_value\n",
    "    def ci_calc(y_hat=None,\n",
    "               y_act=None,\n",
    "               theta_grid=None,\n",
    "               alpha=0.05):\n",
    "\n",
    "        pv_grid = []\n",
    "        for t in theta_grid:\n",
    "            pv = conformal_inf.pvalue_calc(np.concatenate([sc_output['control_pre'], sc_output['control_pst']]),\n",
    "                        np.concatenate([treat_pre, treat_pst]), \n",
    "                            permutations_subset_block,\n",
    "                           treatment_window,\n",
    "                                 h0=t)\n",
    "            pv_grid.append(pv)        \n",
    "        ci_list = [ theta_grid[i] for i in range(len(pv_grid)) if pv_grid[i] > alpha ]\n",
    "        return {'theta_list':theta_grid, 'pvalue_list':pv_grid, 'ci_list':ci_list}\n",
    "\n",
    "    def confidence_interval_calc(counterfactual=None,\n",
    "                                 actual=None, \n",
    "                    permutation_list=None,\n",
    "                   treatment_window=None, \n",
    "                    fine_fine_grid=None,\n",
    "                    significance_level=0.05):\n",
    "        ## Calculate the pvalues that correspond with each of the different theta values in the grid\n",
    "        fine_fine_pvalue_grid = []\n",
    "        for f in fine_fine_grid:\n",
    "            pv = conformal_inf.pvalue_calc(counterfactual=counterfactual,\n",
    "                       actual=actual,\n",
    "                       permutation_list=permutation_list,\n",
    "                       treatment_window=treatment_window,\n",
    "                       h0=f)\n",
    "            fine_fine_pvalue_grid.append(pv)\n",
    "            print(f,pv)\n",
    "\n",
    "        return {'CIgrid_theta':fine_fine_grid,\n",
    "                 'CIgrid_pvalues':fine_fine_pvalue_grid}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593e880",
   "metadata": {},
   "source": [
    "Now calculate the p-value for SC using the conformal inference described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22701b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_settings = {'time units': 25,\n",
    "                'x_units':20,\n",
    "                 'K_dim':10,\n",
    "                'treatment_imp': 10}\n",
    "\n",
    "## Create the dataset\n",
    "df = synth_panel(time_units=data_settings['time units'],\n",
    "    x_units=data_settings['x_units'],\n",
    "    K_dim=data_settings['K_dim'],\n",
    "    treatment_imp=data_settings['treatment_imp'])\n",
    "    \n",
    "tw =  len(df.loc[ df['treatment']==1]['T'].unique())\n",
    "treatment_window = len(df.loc[(df['treatment']==0)]['T'].unique())-tw, tw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24f62f",
   "metadata": {},
   "source": [
    "Decide whether we want to do literally all permutations, or a time-block one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d08622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = np.arange( np.sum(treatment_window) )\n",
    "T_len = len(time_list)\n",
    "\n",
    "## IID permutations\n",
    "permutations_subset = []\n",
    "for r in range(T_len):\n",
    "    entry = [time_list[e] for e in np.random.choice(len(time_list),len(time_list), replace=False )]\n",
    "    if entry not in permutations_subset:\n",
    "        permutations_subset.append(entry)\n",
    "    else:\n",
    "        r-=1\n",
    "\n",
    "## Time block permutations\n",
    "permutations_subset_block = []\n",
    "\n",
    "for i in range(T_len):\n",
    "    half_A = time_list[-1*(T_len-i):]\n",
    "    half_B = time_list[0:i]\n",
    "    scrambled_list = np.concatenate([half_A, half_B]) \n",
    "    permutations_subset_block.append( list(scrambled_list)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "315db115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# time_list = np.arange( np.sum(treatment_window) )\n",
    "# data_settings['permutations_full'] = list(itertools.permutations( time_list )  )\n",
    "# data_settings['permutations_block'] = [np.concatenate( [time_list[e:],\n",
    "#                       [l for l in base_range if l not in time_list[e:] ]]) for e in range(1,len(time_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "924a5f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pvalue from Conformal Inference\n",
      "pvalue 0.04000\n"
     ]
    }
   ],
   "source": [
    "## Estimate the treatment effect without any perturbation\n",
    "control_pre, control_pst, treat_pre, treat_pst = sc_data_from_synth(df)\n",
    "sc_output = syncontrol(X1=control_pst.drop(columns ='T'), X0=control_pre.drop(columns='T'),\n",
    "                      Y1=treat_pst, Y0=treat_pre)\n",
    "## Calculate the residual\n",
    "residual_initial = sc_output['control_pst'] - treat_pst\n",
    "S_q = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "\n",
    "## Now do a whole bunch of treatment time scrambles\n",
    "## We're going to permute over all time-based permutations\n",
    "S_q_pi = []\n",
    "for r in permutations_subset_block:\n",
    "    scrambled_dates = np.array(list(r))\n",
    "    counterfactual_array = np.concatenate([sc_output['control_pre'], sc_output['control_pst']])\n",
    "    actual_array = np.concatenate([treat_pre, treat_pst])\n",
    "    residual = conformal_inf.scrambled_residual( \n",
    "                        counterfactual_array,\n",
    "                        actual_array,\n",
    "                        r,\n",
    "                        treatment_window)    \n",
    "    S_q_pi.append(  conformal_inf.test_statS(1, treatment_window, residual)  )\n",
    "p_value = 1 - np.average( (S_q_pi < S_q) )\n",
    "print('Pvalue from Conformal Inference')\n",
    "print('pvalue {0:7.5f}'.format(p_value) )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48880219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040000000000000036"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conformal_inf.pvalue_calc(np.concatenate([sc_output['control_pre'], sc_output['control_pst']]),\n",
    "                np.concatenate([treat_pre, treat_pst]), \n",
    "                    permutations_subset_block,\n",
    "                   treatment_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e98d5ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_grid_trial = np.arange(-20,20,0.05) \n",
    "\n",
    "ci_output = conformal_inf.ci_calc(y_hat=np.concatenate([sc_output['control_pre'], sc_output['control_pst']]),\n",
    "                   y_act=np.concatenate([treat_pre, treat_pst]),\n",
    "                   theta_grid=fine_grid_trial,\n",
    "                                 alpha=0.05)\n",
    "\n",
    "plt.scatter(x=ci_output['theta_list'],\n",
    "           y=ci_output['pvalue_list'],\n",
    "           color='blue')\n",
    "plt.show()\n",
    "print(ci_output['ci'])\n",
    "# pv_grid = []\n",
    "# for f in fine_grid_trial:\n",
    "#     pv = conformal_inf.pvalue_calc(np.concatenate([sc_output['control_pre'], sc_output['control_pst']]),\n",
    "#                 np.concatenate([treat_pre, treat_pst]), \n",
    "#                     permutations_subset_block,\n",
    "#                    treatment_window,\n",
    "#                          h0=f)\n",
    "#     pv_grid.append(pv)\n",
    "    \n",
    "# plt.scatter(x=fine_grid_trial,\n",
    "#            y=pv_grid,\n",
    "#            color='red')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03576f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2b742",
   "metadata": {},
   "source": [
    "Let's compare this to the Fischer exact test way of calculating the p-value for SC. In this approach, we calculate the impact using each of the control units as the treatment unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ca45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fischer_exact_test_atet = []\n",
    "for u in [e for e in control_pst.columns if e != 'T']:\n",
    "    sc_output_i = syncontrol(X1=control_pst.drop(columns =['T',u]), X0=control_pre.drop(columns=['T',u]),\n",
    "                          Y1=control_pst[u], Y0=control_pre[u])\n",
    "    fischer_exact_test_atet.append( sc_output_i['atet'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = 1 - (fischer_exact_test_atet <= sc_output['atet']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=1, nrows=1, figsize=(9,4))\n",
    "a = ax.hist(fischer_exact_test_atet, color='orangered', alpha=0.50, label='permuted estimates')\n",
    "ax.vlines( sc_output['atet'], 0, a[0].max(), linewidth=5, color='black', label='ATET')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0265e10",
   "metadata": {},
   "source": [
    "## Implementation for Difference-in-Differene models\n",
    "Do the same thing but for difference-in-difference models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add55769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def DiD(X,y, treat_post, fe_list):\n",
    "    '''\n",
    "    X           dataframe\n",
    "    y           array that is our outcome\n",
    "    treat_post  string name of the treatment unit indicator interacted with post indicator\n",
    "    fe_list     columns in X that we want to create fixed effects for\n",
    "    '''\n",
    "    ## \n",
    "    fe_dict = {}\n",
    "    for f in fe_list:\n",
    "        fe_dict[f] = pd.get_dummies(X[f], drop_first=True)\n",
    "    \n",
    "    fe_X = X.rename({treat_post:'txP'}, axis=1)['txP'].copy()        \n",
    "    for f in fe_list:\n",
    "        fe_X = pd.concat([fe_X, fe_dict[f]], axis=1)\n",
    "    \n",
    "    dnd = sm.OLS(y,            \n",
    "           sm.add_constant( fe_X) ).fit()\n",
    "    ft = dnd.fittedvalues\n",
    "    ft[(X[treat_post]==1)] -= dnd.params.txP\n",
    "    return {'est': dnd.params.txP, 'se': dnd.bse.txP, 'pv':dnd.pvalues.txP,\n",
    "           'yhat':dnd.fittedvalues, 'yhat_0': ft}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "## Estimate the DnD model    \n",
    "dnd_output = DiD(X= df,\n",
    "   y= df['Y'],\n",
    "   treat_post= 'treatment',\n",
    "   fe_list = ['unitid','T'])\n",
    "df['yhat_0'] = dnd_output['yhat_0'].values\n",
    "\n",
    "treatment_dates = list( df.loc[(df['post']==1)]['T'].unique() )\n",
    "treat_counterfactual_post = df.loc[(df['treatment_units']==1) &\\\n",
    "                                   (df['T'].isin(treatment_dates))==True].groupby('T')['yhat_0'].mean()\n",
    "treat_actual_post = df.loc[(df['treatment_units']==1) &\\\n",
    "                           (df['T'].isin(treatment_dates))==True].groupby('T')['Y'].mean()\n",
    "\n",
    "## Calculate the residual, which is \n",
    "## the counterfactual of the treatment in the post period if it were control, and the actual\n",
    "residual_initial = treat_counterfactual_post - treat_actual_post\n",
    "S_q_dnd = conformal_inf.test_statS(1, treatment_window, residual_initial)\n",
    "\n",
    "S_q_pi_dnd = []\n",
    "## Now do a whole bunch of treatment time scrambles\n",
    "## Also allow instead to permute over all permutations\n",
    "for r in data_settings['permutations_block']:\n",
    "    scrambled_dates = np.array(list(r))\n",
    "\n",
    "    residual = conformal_inf.scrambled_residual( df.loc[(df['treatment_units']==1)].groupby('T')['yhat_0'].mean(),\n",
    "                       df.loc[(df['treatment_units']==1)].groupby('T')['Y'].mean(),\n",
    "                       scrambled_dates,\n",
    "                       treatment_window)    \n",
    "# for r in range(200):\n",
    "#     scrambled_dates = np.random.choice( np.sum(treatment_window),\n",
    "#                                        np.sum(treatment_window),\n",
    "#                                        replace=False )\n",
    "#     residual = scrambled_sc(df, scrambled_dates, treatment_window[1])\n",
    "    S_q_pi_dnd.append(  conformal_inf.test_statS(1, treatment_window, residual)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ad97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 1 - np.average( (S_q_pi_dnd < S_q_dnd) )\n",
    "print('pvalue {0:7.5f}'.format(p_value) )\n",
    "print('Compare to traditional pvalue {0:7.5f}'.format(dnd_output['pv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('True Estimate: {0}'.format(data_settings['treatment_imp']))\n",
    "print(' SC  Estimate: {0:5.3f}'.format(sc_output['atet'] ) )\n",
    "print(' DiD Estimate: {0:5.3f}'.format(dnd_output['est'] ) )\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(ncols=2,nrows=1, figsize=(13,5))\n",
    "a0 = ax[0].hist(S_q_pi_dnd, label='DiD S-Statistic', color='blue', alpha=0.50)\n",
    "ax[0].vlines( S_q_dnd, 0, a0[0].max(), linewidth=5, color='black', label='ATET')\n",
    "ax[0].set_title('DiD S-Statistic Distribution')\n",
    "\n",
    "a1 = ax[1].hist(S_q_pi, label='DiD S-Statistic', color='orangered', alpha=0.50)\n",
    "ax[1].vlines( S_q, 0, a1[0].max(), linewidth=5, color='black', label='ATET')\n",
    "\n",
    "ax[1].set_title('DiD S-Statistic Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33622e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
