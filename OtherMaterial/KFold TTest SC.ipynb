{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9e3970",
   "metadata": {},
   "source": [
    "# Synthetic Control Bias and Correction with K-Folds\n",
    "Julian Hsu\n",
    "19 Oct 2022\n",
    "\n",
    "This notebook find the bias in standard SC models, and implements the K-Fold procedure from  [Chernozhukov, Wuthrich, and Zhu (2022)](https://arxiv.org/pdf/1812.10820.pdf)  to correct this.\n",
    "\n",
    "### Table of Contents\n",
    "1. K-Fold SC Procedure Overview\n",
    "2. Class of Functions for DGP and SC\n",
    "3. Simulation of Bias\n",
    "4. Implementation of K-Fold SC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314aa58",
   "metadata": {},
   "source": [
    "## K-Fold SC Procedure Overview\n",
    "This comes from the [Chernozhukov, Wuthrich, and Zhu (2022)](https://arxiv.org/pdf/1812.10820.pdf) paper about using a generalized K-fold procedure to estimate an SC model and do inference.\n",
    "\n",
    "We first divide the panel data of pre-treatment data into $K$ consecutive time periods where each block (or fold) is $H_k$ periods. Where $H_k$ has the length $r = min\\{ \\frac{T_0}{K}, T_1 \\}$ . $T_0$ is the number of pre-treatment periods and $T_1$ is the number of post-treatment periods. We then run a SC model on each block (or fold) and use it to estimate the counterfactual on all other blocks. That is, for $k=1,...,K$ we estimate a different ATET:\n",
    "\n",
    "$$\\hat{\\tau}_k = \\dfrac{1}{T_1} \\sum^T_{t=T_0+1} \\big( Y_{0t} - \\sum^N_{i=1} \\hat{\\omega_{i,(k)}} Y_{it} \\big) - \\dfrac{1}{|H_k|}\\sum_{t \\in H_k} \\big( Y_{0t} - \\sum^N_{i=1} \\hat{\\omega_{i,(k)}} Y_{it} \\big) $$\n",
    "$$\\hat{\\tau} = \\dfrac{1}{K}\\sum^K_{k=1} \\hat{\\tau}_k$$\n",
    "Where $\\hat{\\omega_{i,(k)}} $ is obtained by training the SC model on the data not in block $k$.\n",
    "\n",
    "Note that the first summation is the standard SC model with the observed treated's post-treatment outcome $Y_{0t}$ minus the estimated counterfactual based on the estimated weights applied to the controls' post-treatment outcome. The second summation is the difference in the pre-treatment outcomes, otherwise known as placebo estimates. We need this second summation because there is a risk of bias in the first summation. This paper shows the estimator is biased, and can be corrected by doing the same comparison by for the *pre-treatment* periods.\n",
    "\n",
    "Where does this bias come from? If the data is high-dimensional by having a lot of time periods $T_0 >> N$, then you can have an error from estimation. \n",
    "\n",
    "This K-fold model also offers standard errors that do not depend on a Long-Run Variance (LRV). The t-statistic of K-fold model estimator is:\n",
    "\n",
    "$$\\mathbb{T}_K = \\dfrac{\\sqrt{K}(\\hat{\\tau} - \\tau_0 )}{ \\hat{\\sigma}_{\\hat{k}} }$$\n",
    "$$\\text{  where  } \\hat{\\sigma}_{\\hat{k}} = \\sqrt{1 + \\frac{K \\cdot r}{T_1}} \\sqrt{\\frac{1}{K-1} \\sum^K_{k=1}(\\hat{\\tau}_k  -\\hat{\\tau} )^2   }   $$\n",
    "\n",
    "From here, we can construct a $(1-\\alpha)$ confidence interval:\n",
    "\n",
    "$$CI_K(1-\\alpha) = \\hat{\\tau} \\mp \\mathbb{cv}(1-\\alpha/2) \\cdot \\frac{\\hat{\\sigma}_k}{\\sqrt{K}}  $$\n",
    "where $\\mathbb{cv}(1-\\alpha/2)$ is the $(1-\\alpha/2)$-th quantile of the t distribution with $K-1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bf38b",
   "metadata": {},
   "source": [
    "## Class of Functions for DGP and SC\n",
    "### DGP\n",
    "We will have a function, `panel_station` which outputs multiple types of outcomes following [Chernozhukov et al.'s $\\tau$-test SC paper, (2018)](https://arxiv.org/abs/1812.10820).\n",
    "\n",
    "Stationary Trend:\n",
    "$$Y_{it} = \\lambda_i f_t + \\eta_{it} $$\n",
    "Non-Stationary Trend with a random walk:\n",
    "$$Y_{it} = \\theta_{t} +  \\lambda_i f_t + \\eta_{it} $$\n",
    "Non-Stationary Trend with a random walk and sparse deviation:\n",
    "$$Y_{it} = \\theta_{1t} + 1\\{i=1\\}\\theta_{2t}  \\lambda_i f_t + \\eta_{it} $$\n",
    "Heterogeneous Trends:\n",
    "$$Y_{it} = \\theta_{it} +  \\lambda_i f_t + \\eta_{it} $$\n",
    "\n",
    "where\n",
    "$$\\eta_{it} = \\rho_i \\eta_{it-1} + \\epsilon_{it}, \\epsilon_{it} \\sim N(0,\\sigma^2_\\epsilon) $$\n",
    "$$f_t \\sim N(0, \\sigma^2_f) $$\n",
    "$$\\theta_t = \\theta_{t-1} + \\xi_t , \\xi_t \\sim N(0,1)$$\n",
    "$$\\theta_{1t} = \\theta_{1t-1} + \\xi_{1t}, \\xi_{1t} \\sim N(0,1) $$\n",
    "$$\\theta_{2t} = \\theta_{2t-1} + \\xi_{2t}, \\xi_{1t} \\sim N(0,1) $$\n",
    "$$\\theta_{it} = i + i \\cdot t$$\n",
    "### SC Models\n",
    "For simplicity, focus on the Abadie, Diamond, Hainmueller (2010) SC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17484ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from IPython.display import display    \n",
    "\n",
    "import scipy.stats \n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b4d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dgp:    \n",
    "    def panel_station(seed_number = 2739,\n",
    "                     pre_time_units = 20,\n",
    "                     pst_time_units = 5,\n",
    "                     x_units_control = 15,\n",
    "                     x_units_treat = 5,                      \n",
    "                     K_dim = 5,\n",
    "                     at = 2):\n",
    "        '''\n",
    "        seed_number  random_number_set\n",
    "        pre_time_units   how many pre-treatment time periods?\n",
    "        pst_time_units   how many post-treatment time periods?\n",
    "        x_units      how many units?\n",
    "        K_dim        how many covariates (assume uniform)\n",
    "        at           ATET estimate\n",
    "        '''  \n",
    "        xfun = np.random.RandomState(seed_number)\n",
    "        time_units = pre_time_units + pst_time_units\n",
    "        t_range = pd.date_range(pd.to_datetime('2020/01/01'), periods=time_units, freq=\"M\")\n",
    "        x_units = x_units_control+x_units_treat\n",
    "        u_range = range(x_units)\n",
    "        sigma_epsilon = 1\n",
    "        rho = 0.75\n",
    "\n",
    "\n",
    "        df_return = pd.DataFrame(index=list(u_range)*time_units, \n",
    "                     columns=['date'],\n",
    "                     data= np.array( [ [p]*x_units for p in t_range] ).flatten() )\n",
    "        df_return.reset_index(names='unitid', inplace=True)\n",
    "\n",
    "        df_return.sort_values(by=['unitid','date'], ascending=True, inplace=True)\n",
    "        df_return['_f'] = np.log( 1+df_return.groupby('unitid').rank() )\n",
    "\n",
    "        ## Lambda is time-invariant\n",
    "        df_return['_lambda'] = xfun.uniform(0,1, len(df_return) )\n",
    "        df_return['_lambda'] = df_return.groupby('unitid')['_lambda'].mean()\n",
    "        df_return['_lambda'] = df_return['_lambda'].fillna(df_return.groupby('unitid')['_lambda'].transform('mean'))\n",
    "\n",
    "        ## eta is lagged\n",
    "        df_return['_eta'] = xfun.normal(0, sigma_epsilon, len(df_return))\n",
    "        df_return['_eta'] = df_return.groupby('unitid').shift(1)['_eta'].fillna(0)*rho + df_return['_eta']\n",
    "\n",
    "        ## xi is unit-invariant\n",
    "        ## create unit-invariant AR values\n",
    "        def ar1(error_name, theta_name):\n",
    "            df_return[error_name] = xfun.normal(0, 1, len(df_return))\n",
    "            df_return[error_name] = df_return.groupby('unitid')[error_name].mean()\n",
    "            df_return[error_name] = df_return[error_name].fillna(df_return.groupby('unitid')[error_name].transform('mean'))\n",
    "            df_return[theta_name] = df_return.groupby('unitid').shift(1)[error_name].fillna(0)*rho + df_return[error_name]\n",
    "        ar1('_xi', '_theta_t')    \n",
    "        ar1('_xi1', '_theta_t1')    \n",
    "        ar1('_xi2', '_theta_t2')    \n",
    "\n",
    "        ## Allow _theta_t2 to be sparse\n",
    "        ## It is allowed to be non-zero for only one unit\n",
    "        random_unit = xfun.choice(x_units,1)[0]\n",
    "        df_return.loc[df_return['unitid']!=random_unit, '_theta_t2'] = 0\n",
    "\n",
    "        ## heterogeneous trends\n",
    "        df_return['_theta_it'] = (df_return['unitid']+1) + np.log(df_return['unitid']+1)*df_return['_f']\n",
    "        ## Assign treatment status\n",
    "        df_return['treated_unit'] = (df_return['unitid'].isin(np.arange(x_units_treat))).astype(float)\n",
    "        df_return['post'] = (df_return['date'].isin(t_range[-1*pst_time_units:])).astype(float)\n",
    "        df_return['W'] =     df_return['treated_unit']*    df_return['post']\n",
    "        ## Assign outcome ot treated values\n",
    "        df_return['y_station']      = df_return['W']*at + df_return['_lambda'] * df_return['_f'] + df_return['_eta']\n",
    "        df_return['y_nonstation_rw']= df_return['W']*at + df_return['y_station'] + df_return['_theta_t']\n",
    "        df_return['y_nonstation_rw_sparse'] = df_return['W']*at + df_return['y_station'] + df_return['_theta_t1'] + df_return['_theta_t2']\n",
    "        df_return['y_nonstation_het']       = df_return['W']*at + df_return['y_station'] + df_return['_theta_it']\n",
    "        \n",
    "        df_return['unitid'] = df_return['unitid'].apply(str)        \n",
    "        return df_return\n",
    "    \n",
    "    def clean_and_input_data(dataset=None, \n",
    "                             treatment='treated_unit', \n",
    "                             date='T',\n",
    "                             post='post', outcome='Y'):\n",
    "        \n",
    "        C_pre = dataset.loc[(dataset[treatment]==0) & (dataset[post]==0)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        C_pst = dataset.loc[(dataset[treatment]==0) & (dataset[post]==1)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pre = dataset.loc[(dataset[treatment]==1) & (dataset[post]==0)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        T_pst = dataset.loc[(dataset[treatment]==1) & (dataset[post]==1)].pivot_table(columns='unitid',\n",
    "                                                index=date,\n",
    "                                                values=outcome)\n",
    "        return {'C_pre':C_pre, 'C_pst':C_pst, 'T_pre':T_pre, 'T_pst':T_pst}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9109ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class di:\n",
    "    def estimate_mu_omega(treatment_pre, control_pre, alpha_lambda_0):\n",
    "        alpha_0, lambda_0 = alpha_lambda_0[0], alpha_lambda_0[1]\n",
    "        elnet = ElasticNet(random_state=2736, alpha=alpha_0, l1_ratio=lambda_0)\n",
    "        elnet.fit(control_pre, treatment_pre )\n",
    "        ## Output interpretable weights\n",
    "        try:\n",
    "            df_weights= pd.DataFrame(data=zip(treatment_pre.columns,\n",
    "                                              elnet.coef_.T\n",
    "                                             ))\n",
    "#             df_weights = pd.DataFrame(index=np.arange(len(elnet.coef_)), \n",
    "#                          data=elnet.coef_.T,\n",
    "#                         columns=treatment_pre.columns)\n",
    "        except:\n",
    "            df_weights = pd.DataFrame(index=np.arange(len(elnet.coef_)), \n",
    "                         data=elnet.coef_.T)        \n",
    "        return {'mu': elnet.intercept_, 'omega': elnet.coef_, 'weights':df_weights, 'full':elnet}\n",
    "\n",
    "    def predict_mu_omega(treatment_pre, control_pre, alpha_lambda_0, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the DI model\n",
    "        holdout_dict = di.estimate_mu_omega(treatment_holdout, control_holdout, alpha_lambda_0)\n",
    "        ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "        diff_holdout = treatment_holdout       - np.dot(control_holdout, holdout_dict['omega'].T)+holdout_dict['mu']\n",
    "        diff_holdout_mse = (diff_holdout**2).mean()\n",
    "        diff_nonholdout = treatment_nonholdout - np.dot(control_nonholdout, holdout_dict['omega'].T)+holdout_dict['mu']\n",
    "        diff_nonholdout_mse = (diff_nonholdout**2).mean()\n",
    "        \n",
    "        return {'mu':     holdout_dict['mu'],\n",
    "               'omega':   holdout_dict['omega'],\n",
    "               'weights': holdout_dict['weights'],\n",
    "               'full':    holdout_dict['full'],\n",
    "               'mse_holdout': diff_holdout_mse,\n",
    "               'mse_nonholdout':diff_nonholdout_mse}\n",
    "\n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:] - output_df[c+'_est'][treatment_periods:]\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5264d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Also code up the ADH weights\n",
    "## Abadie/Diamond/Hainmueller    \n",
    "from typing import List\n",
    "from operator import add\n",
    "from toolz import reduce, partial\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "class adh:\n",
    "    ## Define loss function\n",
    "    def loss_w(W, X, y) -> float:\n",
    "        return np.sqrt(np.mean((y - X.dot(W))**2))\n",
    "\n",
    "    def get_w(X, y):\n",
    "        ## Initialize at sample average with some noise\n",
    "        w_start = [1/X.shape[1]]*X.shape[1]+np.random.uniform(-0.005,0.005, X.shape[1])\n",
    "    #     w_start = np.ones(X.shape[1])\n",
    "\n",
    "        weights = fmin_slsqp(partial(adh.loss_w, X=X, y=y),\n",
    "                             np.array(w_start),\n",
    "                             f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                             iter=50000, \n",
    "                             bounds=[(0.0, 1.0)]*len(w_start),\n",
    "                             disp=False)\n",
    "        return weights   \n",
    "    \n",
    "    def predict_omega(treatment_pre, control_pre, holdout_windows):\n",
    "        ## Don't use all the control data\n",
    "        ## Make sure that the holdout windows add up to the total number of pre-treatment units\n",
    "        if (holdout_windows[0]+holdout_windows[1] != len(control_pre)):\n",
    "            print('the arg holdout_windows does not add up to the number of time units!')\n",
    "            print('holdout_windows = {0}'.format(holdout_windows))\n",
    "            print('total number of time periods = {0}'.format(len(control_pre)))\n",
    "        else:\n",
    "            pass    \n",
    "        ## Define the holdout samples\n",
    "        control_holdout = control_pre[0:holdout_windows[0]]\n",
    "        treatment_holdout = treatment_pre[0:holdout_windows[0]]    \n",
    "        \n",
    "        control_nonholdout = control_pre[holdout_windows[0]:]\n",
    "        treatment_nonholdout = treatment_pre[holdout_windows[0]:]\n",
    "        \n",
    "        ## Estimate the CL model\n",
    "        ## Let's loop over different treatment units.\n",
    "        holdout_dict = {}\n",
    "        holdout_dict['omega'] = []\n",
    "        holdout_dict['weights'] = []\n",
    "        diff_holdout_mse = []\n",
    "        diff_nonholdout_mse = []\n",
    "        for t in treatment_pre.columns:\n",
    "            t_dict = adh.get_w(control_holdout,treatment_holdout[t])\n",
    "            ## Estimate measure of fit for the hold out and non-holdout sample\n",
    "            diff_h = treatment_holdout[t]       - np.dot(control_holdout, t_dict.T)\n",
    "            diff_h_mse = (diff_h**2).mean()\n",
    "            diff_nh = treatment_nonholdout[t] - np.dot(control_nonholdout, t_dict.T)\n",
    "            diff_nh_mse = (diff_nh**2).mean()\n",
    "\n",
    "            holdout_dict['omega'].append(t_dict)\n",
    "            holdout_dict['weights'].append(t_dict)\n",
    "            diff_holdout_mse.append(diff_h_mse)\n",
    "            diff_nonholdout_mse.append(diff_nh_mse)\n",
    "\n",
    "        holdout_dict['omega'] = np.array(holdout_dict['omega'])\n",
    "        holdout_dict['mse_holdout'] =np.mean(diff_holdout_mse)\n",
    "        holdout_dict['mse_nonholdout'] =np.mean(diff_holdout_mse)        \n",
    "        \n",
    "        return holdout_dict    \n",
    "    \n",
    "    def sc_style_results(treatment_pre, treatment_pst, control_pre, control_pst, mu,omega):\n",
    "        final_X = pd.concat([treatment_pre, treatment_pst], axis=0)\n",
    "        control_X = pd.concat([control_pre, control_pst], axis=0)\n",
    "\n",
    "        control_df = mu + pd.DataFrame(data=np.dot(control_X, omega.T), columns=[ l+'_est' for l in final_X.columns ])\n",
    "        control_df.index = final_X.index\n",
    "        \n",
    "        output_df = control_df.join(final_X)\n",
    "        \n",
    "        treatment_periods = -1*len(treatment_pst)\n",
    "        atet_df = pd.DataFrame()\n",
    "        for c in [l for l in output_df.columns if '_est' not in l]:\n",
    "            diff = output_df[c][treatment_periods:] - output_df[c+'_est'][treatment_periods:]\n",
    "            atet_df[c] = diff\n",
    "        \n",
    "        return {'atet': atet_df , 'predict_est':output_df}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb68a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc7c53bb",
   "metadata": {},
   "source": [
    "## Simulation of Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128b233a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m treatment_window_pre_treatment \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(treatment_window[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.75\u001b[39m) ,treatment_window[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(treatment_window[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.75\u001b[39m)   ]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m## Run ADH Model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m ao3 \u001b[38;5;241m=\u001b[39m \u001b[43madh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdi_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT_pre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdi_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC_pre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatment_window_pre_treatment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m adh_output \u001b[38;5;241m=\u001b[39m adh\u001b[38;5;241m.\u001b[39msc_style_results(di_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_pre\u001b[39m\u001b[38;5;124m'\u001b[39m], di_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_pst\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     49\u001b[0m                     di_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_pre\u001b[39m\u001b[38;5;124m'\u001b[39m], di_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_pst\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     50\u001b[0m                     np\u001b[38;5;241m.\u001b[39mzeros(di_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_pst\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray(ao3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momega\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     51\u001b[0m sim_est\u001b[38;5;241m=\u001b[39m  adh_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]   \n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36madh.predict_omega\u001b[0;34m(treatment_pre, control_pre, holdout_windows)\u001b[0m\n\u001b[1;32m     48\u001b[0m diff_nonholdout_mse \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m treatment_pre\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 50\u001b[0m     t_dict \u001b[38;5;241m=\u001b[39m \u001b[43madh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtreatment_holdout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m## Estimate measure of fit for the hold out and non-holdout sample\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     diff_h \u001b[38;5;241m=\u001b[39m treatment_holdout[t]       \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(control_holdout, t_dict\u001b[38;5;241m.\u001b[39mT)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36madh.get_w\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     w_start \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m*\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.005\u001b[39m,\u001b[38;5;241m0.005\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     w_start = np.ones(X.shape[1])\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mfmin_slsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43madh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mf_eqcons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_slsqp_py.py:206\u001b[0m, in \u001b[0;36mfmin_slsqp\u001b[0;34m(func, x0, eqcons, f_eqcons, ieqcons, f_ieqcons, bounds, fprime, fprime_eqcons, fprime_ieqcons, args, iter, acc, iprint, disp, full_output, epsilon, callback)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f_ieqcons:\n\u001b[1;32m    203\u001b[0m     cons \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mineq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m: f_ieqcons, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m: fprime_ieqcons,\n\u001b[1;32m    204\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m: args}, )\n\u001b[0;32m--> 206\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_slsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfprime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_slsqp_py.py:432\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    429\u001b[0m     c \u001b[38;5;241m=\u001b[39m _eval_constraint(x, cons)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# gradient evaluation required\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     g \u001b[38;5;241m=\u001b[39m append(\u001b[43mwrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m    433\u001b[0m     a \u001b[38;5;241m=\u001b[39m _eval_con_normals(x, cons, la, n, m, meq, mieq)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m majiter \u001b[38;5;241m>\u001b[39m majiter_prev:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# call callback if major iteration has incremented\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_optimize.py:277\u001b[0m, in \u001b[0;36m_clip_x_for_func.<locals>.eval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(x):\n\u001b[1;32m    276\u001b[0m     x \u001b[38;5;241m=\u001b[39m _check_clip_x(x, bounds)\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:273\u001b[0m, in \u001b[0;36mScalarFunction.grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36madh.loss_w\u001b[0;34m(W, X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_w\u001b[39m(W, X, y) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3438\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3436\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   3441\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:11856\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11838\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11839\u001b[0m     _num_doc,\n\u001b[1;32m  11840\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11854\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11855\u001b[0m ):\n\u001b[0;32m> 11856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:11408\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11402\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11406\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:11360\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11350\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11355\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m  11356\u001b[0m     )\n\u001b[1;32m  11357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11358\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11359\u001b[0m     )\n\u001b[0;32m> 11360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4819\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4816\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4817\u001b[0m     )\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py:690\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;129m@disallow\u001b[39m(PeriodDtype)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;129m@bottleneck_switch\u001b[39m()\n\u001b[1;32m    658\u001b[0m \u001b[38;5;129m@_datetimelike_compat\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m     mask: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    665\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    Compute the mean of the element along an axis ignoring NaNs\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    1.5\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 690\u001b[0m     values, mask, dtype, dtype_max, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m     dtype_sum \u001b[38;5;241m=\u001b[39m dtype_max\n\u001b[1;32m    694\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py:344\u001b[0m, in \u001b[0;36m_get_values\u001b[0;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(dtype) \u001b[38;5;129;01mor\u001b[39;00m is_bool_dtype(dtype):\n\u001b[1;32m    343\u001b[0m     dtype_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_float_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    345\u001b[0m     dtype_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values, mask, dtype, dtype_max, fill_value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py:1276\u001b[0m, in \u001b[0;36mis_float_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_float_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;124;03m    Check whether the provided array or dtype is of a float dtype.\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _is_dtype_type(arr_or_dtype, \u001b[43mclasses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloating\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py:147\u001b[0m, in \u001b[0;36mclasses\u001b[0;34m(*klasses)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_value\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclasses\u001b[39m(\u001b[38;5;241m*\u001b[39mklasses) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate if the tipo is a subclass of the klasses.\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m tipo: \u001b[38;5;28missubclass\u001b[39m(tipo, klasses)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "settings ={'atet_gt': 5,\n",
    "          'T0':20,\n",
    "          'N':15}\n",
    "df_sim = pd.DataFrame()\n",
    "y_outcome = ['y_station', 'y_nonstation_rw']\n",
    "#              , 'y_nonstation_rw_sparse',\n",
    "#        'y_nonstation_het']\n",
    "adh_estimates = []\n",
    "sim_range = range(500)\n",
    "t0_range = [5,20,100]\n",
    "for t0 in t0_range:\n",
    "    for sim in sim_range:\n",
    "        df = dgp.panel_station(seed_number=sim,\n",
    "                         pre_time_units=t0,\n",
    "                         pst_time_units=5,\n",
    "                         x_units_control = settings['N'],\n",
    "                         x_units_treat = 1,\n",
    "                         K_dim = 3,\n",
    "                         at=settings['atet_gt'])\n",
    "        for y_iter in y_outcome:\n",
    "            ## Clean data\n",
    "            di_dict = dgp.clean_and_input_data(dataset=df,\n",
    "                                               treatment='treated_unit', \n",
    "                                               date='date',\n",
    "                                               post='post',\n",
    "                                              outcome=y_iter)\n",
    "\n",
    "            ## Create Primitives\n",
    "            tw =  len(df.loc[ df['W']==1]['date'].unique())\n",
    "            treatment_window = len(df.loc[(df['W']==0)]['date'].unique())-tw, tw\n",
    "\n",
    "            time_list = np.arange( np.sum(treatment_window) )\n",
    "            T_len = len(time_list)\n",
    "\n",
    "            ## Time block permutations\n",
    "            permutations_subset_block = []\n",
    "\n",
    "            for i in range(T_len):\n",
    "                half_A = time_list[-1*(T_len-i):]\n",
    "                half_B = time_list[0:i]\n",
    "                scrambled_list = np.concatenate([half_A, half_B]) \n",
    "                permutations_subset_block.append( list(scrambled_list)  )\n",
    "\n",
    "            treatment_window_pre_treatment = [int(treatment_window[0]*0.75) ,treatment_window[0]-int(treatment_window[0]*0.75)   ]\n",
    "\n",
    "            ## Run ADH Model\n",
    "            ao3 = adh.predict_omega(di_dict['T_pre'], di_dict['C_pre'], treatment_window_pre_treatment)\n",
    "            adh_output = adh.sc_style_results(di_dict['T_pre'], di_dict['T_pst'],\n",
    "                                di_dict['C_pre'], di_dict['C_pst'],\n",
    "                                np.zeros(di_dict['T_pst'].shape[1]), np.array(ao3['omega']))\n",
    "            sim_est=  adh_output['atet'].mean(axis=0).values[0]   \n",
    "            row = pd.DataFrame(index=[sim], data={'atet':sim_est,\n",
    "                                   'gt':settings['atet_gt'],\n",
    "                                   'T0':t0,\n",
    "                                                  'y':y_iter,\n",
    "                                   'N':settings['N']})\n",
    "            df_sim = pd.concat([df_sim, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fe11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=len(y_outcome),ncols=1, figsize=(20,10))\n",
    "for y_i, y_iter in zip(range(len(y_outcome)), y_outcome):\n",
    "    for t0 in t0_range:\n",
    "        if t0==5:\n",
    "            color='red'\n",
    "        elif t0==10:\n",
    "            color='royalblue'\n",
    "        else:\n",
    "            color='seagreen'\n",
    "        a = ax[y_i].hist(df_sim.loc[(df_sim['T0']==t0) & (df_sim['y']==y_iter)]['atet'], \n",
    "                    density=True, alpha=0.25, color=color,\n",
    "                   label='T0={0}'.format(t0))\n",
    "        df_sim.loc[(df_sim['T0']==t0) & (df_sim['y']==y_iter)]['atet'].plot(kind='density',\n",
    "                                                                            ax=ax[y_i],\n",
    "                                                                            label='T0={0}, Density'.format(t0),\n",
    "                                                                           color=color)\n",
    "        ax[y_i].vlines(x= settings['atet_gt'], \n",
    "                       color='black',\n",
    "                  ymin=0, ymax=a[0].max(),\n",
    "                  linewidth=5)\n",
    "    ax[y_i].legend(title='T0 with \\nN={0} Control Units'.format(settings['N']))\n",
    "    ax[y_i].set_title('Outcome = {0}'.format(y_iter))\n",
    "    ax[y_i].grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d747d06",
   "metadata": {},
   "source": [
    "### Implementation of K-Fold SC\n",
    "K-Fold SC nests *any* sort of SC model (ie Abadie/Diamond/Hainmueller, Doudchenko/Imbens, etc). Therefore, we just need to create an outer loop/wrap that does the test and training data splitting for training and scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d80792",
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 10\n",
    "T1 = 10\n",
    "K  = 5\n",
    "\n",
    "import copy\n",
    "\n",
    "## Figure out how many blocks we will have.\n",
    "## Allow the user to propose one, but this can be over-written if T1 < T0/K.\n",
    "if (int(T0 / K) > T1):\n",
    "    print('User override because T0/K < T1 --> {0}/{1} < {2}'.format(T0,T1,K))\n",
    "    r = T1\n",
    "    K = T0/r\n",
    "    print(' New K = {0}'.format(K))\n",
    "else:\n",
    "    r = int(T0/K)\n",
    "    \n",
    "## Split the pre-training data. If we cannot split it into equal portions, \n",
    "## bias towards a larger piece at the end.\n",
    "pre_treatment_event_list = np.arange(T0)\n",
    "# [ list(pre_treatment_event_list[i:i*Hk+Hk] ) for i in range(K) ]\n",
    "Hk = [ list( np.arange( (k-1)*r+1+1, k*r+1+1 ) ) for k in np.arange(K)]\n",
    "# print( '{0} , {1}'.format( (k-1)*r+1, k*r))\n",
    "\n",
    "## Create training and test pre-treatment indices.\n",
    "kfold_sets = {}\n",
    "for r in np.arange(K):   \n",
    "    kfold_sets[r] = {'test':Hk[r], \n",
    "                    'training': [p for p in  [item for x in Hk for item in x] if p not in Hk[r]]}\n",
    "    \n",
    "    \n",
    "## For each entry in this dictionary, estimate an SC model using the training set. \n",
    "## We want to know the estimate this set gives us on the test set's post-treatment\n",
    "## and pre-treatment outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc711697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean data for SC model\n",
    "di_dict = dgp.clean_and_input_data(dataset=df, \n",
    "                                   treatment='treated_unit', \n",
    "                                   date='date',\n",
    "                                   post='post',\n",
    "                                   outcome='y_station')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dce8118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADH Output:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>5.318099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>6.416318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>6.055605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>4.360393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>4.818702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "date                \n",
       "2020-06-30  5.318099\n",
       "2020-07-31  6.416318\n",
       "2020-08-31  6.055605\n",
       "2020-09-30  4.360393\n",
       "2020-10-31  4.818702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## Run ADH Model on the whole data set\n",
    "ao3 = adh.predict_omega(di_dict['T_pre'], di_dict['C_pre'], treatment_window_pre_treatment)\n",
    "adh_output = di.sc_style_results(di_dict['T_pre'], di_dict['T_pst'],\n",
    "                    di_dict['C_pre'], di_dict['C_pst'],\n",
    "                    np.zeros(di_dict['T_pst'].shape[1]), np.array(ao3['omega']))\n",
    "display('ADH Output:')\n",
    "display(  adh_output['atet'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b1c14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start to do this for different train/test sets following the kfold approach\n",
    "\n",
    "test_dates = df['date'].sort_values().unique()[kfold_sets[0]['test']]\n",
    "training_dates = df['date'].sort_values().unique()[kfold_sets[0]['training']]\n",
    "df_training_subset = df.loc[df['date'].isin(test_dates)==False]\n",
    "\n",
    "df_test_subset = df.loc[df['date'].isin(training_dates)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea77777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean data for SC model\n",
    "di_dict_training = dgp.clean_and_input_data(dataset=df_training_subset, \n",
    "                                   treatment='treated_unit', \n",
    "                                   date='date',\n",
    "                                   post='post',\n",
    "                                   outcome='y_station')\n",
    "## Clean data for SC model\n",
    "di_dict_test = dgp.clean_and_input_data(dataset=df_test_subset, \n",
    "                                   treatment='treated_unit', \n",
    "                                   date='date',\n",
    "                                   post='post',\n",
    "                                   outcome='y_station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43263353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADH Output:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>-0.110176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>-0.573141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "date                \n",
       "2020-01-31 -0.110176\n",
       "2020-02-29 -0.573141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f=np.ceil(di_dict_training['C_pre'].shape[0]*0.66)\n",
    "g = di_dict_training['C_pre'].shape[0] - f\n",
    "treatment_window_pre_treatment = [int(f),int(g)]\n",
    "## Run ADH Model on the whole data set\n",
    "ao3 = adh.predict_omega(di_dict_training['T_pre'], di_dict_training['C_pre'], treatment_window_pre_treatment)\n",
    "adh_output = di.sc_style_results(di_dict_test['T_pre'], di_dict_test['T_pst'],\n",
    "                    di_dict_test['C_pre'], di_dict_test['C_pst'],\n",
    "                    np.zeros(di_dict_training['T_pst'].shape[1]), np.array(ao3['omega']))\n",
    "display('ADH Output:')\n",
    "display(  adh_output['atet'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kfold_sc:\n",
    "    de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2a03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a955c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
